StanFunction;Arguments;ReturnType;Documentation;
beta;~;real;Increment target log probability density with `beta_lupdf(theta | alpha, beta)`.;
beta_lpdf;(reals theta | reals alpha, reals beta);real;The log of the beta density of `theta` in $[0,1]$ given positive prior\nsuccesses (plus one) alpha and prior failures (plus one) beta\n;
beta_lupdf;(reals theta | reals alpha, reals beta);real;The log of the beta density of `theta` in $[0,1]$ given positive prior\nsuccesses (plus one) alpha and prior failures (plus one) beta\ndropping constant additive terms\n;
beta_cdf;(reals theta | reals alpha, reals beta);real;The beta cumulative distribution function of `theta` in $[0,1]$ given\npositive prior successes (plus one) alpha and prior failures (plus\none) beta\n;
beta_lcdf;(reals theta | reals alpha, reals beta);real;The log of the beta cumulative distribution function of `theta` in\n$[0,1]$ given positive prior successes (plus one) alpha and prior\nfailures (plus one) beta\n;
beta_lccdf;(reals theta | reals alpha, reals beta);real;The log of the beta complementary cumulative distribution function of\n`theta` in $[0,1]$ given positive prior successes (plus one) alpha and\nprior failures (plus one) beta\n;
beta_rng;(reals alpha, reals beta);R;Generate a beta variate with positive prior successes (plus one) alpha\nand prior failures (plus one) beta may only be used in transformed data and\ngenerated quantities blocks. For a description of argument and return types, see\nsection [vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
beta_proportion;~;real;Increment target log probability density with `beta_proportion_lupdf(theta | mu, kappa)`.;
beta_proportion_lcdf;(reals theta | reals mu, reals kappa);real;The log of the beta_proportion cumulative distribution function of\n`theta` in $(0,1)$ given mean mu and precision kappa\n;
beta_proportion_lccdf;(reals theta | reals mu, reals kappa);real;The log of the beta_proportion complementary cumulative distribution\nfunction of `theta` in $(0,1)$ given mean mu and precision kappa\n;
beta_proportion_rng;(reals mu, reals kappa);R;Generate a beta_proportion variate with mean mu and precision kappa\nmay only be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
wishart;~;real;Increment target log probability density with `wishart_lupdf(W | nu, Sigma)`.;
wishart_lpdf;(matrix W | real nu, matrix Sigma);real;Return the log of the Wishart density for symmetric and positive-definite\nmatrix `W` given degrees of freedom `nu` and symmetric and\npositive-definite scale matrix `Sigma`.\n;
wishart_lupdf;(matrix W | real nu, matrix Sigma);real;Return the log of the Wishart density for symmetric and positive-definite\nmatrix `W` given degrees of freedom `nu` and symmetric and\npositive-definite scale matrix `Sigma` dropping constant additive terms.\n;
wishart_rng;(real nu, matrix Sigma);matrix;Generate a Wishart variate with degrees of freedom `nu` and symmetric\nand positive-definite scale matrix `Sigma` may only be used in\ntransformed data and generated quantities blocks.\n;
wishart_cholesky_lpdf;(matrix L_W | real nu, matrix L_S);real;Return the log of the Wishart density for lower-triangular Cholesky factor `L_W`\ngiven degrees of freedom `nu` and lower-triangular Cholesky factor of the\nscale matrix `L_S`.\n;
wishart_cholesky_lupdf;(matrix L_W | real nu, matrix L_S);real;Return the log of the Wishart density for lower-triangular Cholesky factor of `L_W`\ngiven degrees of freedom `nu` and lower-triangular Cholesky factor of the\nscale matrix `L_S` dropping constant additive terms.\n;
wishart_cholesky_rng;(real nu, matrix L_S);matrix;Generate the Cholesky factor of a Wishart variate with degrees of freedom `nu` and\nlower-triangular Cholesky factor of the scale matrix `L_S` may only be used in\ntransformed data and generated quantities blocks\n;
inv_wishart;~;real;Increment target log probability density with `inv_wishart_lupdf(W | nu, Sigma)`.;
inv_wishart_lpdf;(matrix W | real nu, matrix Sigma);real;Return the log of the inverse Wishart density for symmetric and\npositive-definite matrix `W` given degrees of freedom `nu` and symmetric\nand positive-definite scale matrix `Sigma`.\n;
inv_wishart_lupdf;(matrix W | real nu, matrix Sigma);real;Return the log of the inverse Wishart density for symmetric and\npositive-definite matrix `W` given degrees of freedom `nu` and symmetric\nand positive-definite scale matrix `Sigma` dropping constant additive terms.\n;
inv_wishart_rng;(real nu, matrix Sigma);matrix;Generate an inverse Wishart variate with degrees of freedom `nu` and\nsymmetric and positive-definite scale matrix `Sigma` may only be used\nin transformed data and generated quantities blocks.\n;
inv_wishart_cholesky_lpdf;(matrix L_W | real nu, matrix L_S);real;Return the log of the inverse Wishart density for lower-triangular Cholesky factor `L_W`\ngiven degrees of freedom `nu` and lower-triangular Cholesky factor of the\nscale matrix `L_S`.\n;
inv_wishart_cholesky_lupdf;(matrix L_W | real nu, matrix L_S);real;Return the log of the inverse Wishart density for lower-triangular Cholesky factor of `L_W`\ngiven degrees of freedom `nu` and lower-triangular Cholesky factor of the\nscale matrix `L_S` dropping constant additive terms.\n;
inv_wishart_cholesky_rng;(real nu, matrix L_S);matrix;Generate the Cholesky factor of an inverse Wishart variate with degrees of freedom `nu` and\nlower-triangular Cholesky factor of the scale matrix `L_S` may only be used in\ntransformed data and generated quantities blocks.\n;
multi_normal;~;real;Increment target log probability density with `multi_normal_lupdf(y | mu, Sigma)`.;
multi_normal_lpdf;(vectors y | vectors mu, matrix Sigma);real;The log of the multivariate normal density of vector(s) y given\nlocation vector(s) mu and covariance matrix Sigma\n;
multi_normal_lupdf;(vectors y | vectors mu, matrix Sigma);real;The log of the multivariate normal density of vector(s) y given\nlocation vector(s) mu and covariance matrix Sigma dropping constant additive\nterms\n;
multi_normal_lpdf;(vectors y | row_vectors mu, matrix Sigma);real;The log of the multivariate normal density of vector(s) y given\nlocation row vector(s) mu and covariance matrix Sigma\n;
multi_normal_lupdf;(vectors y | row_vectors mu, matrix Sigma);real;The log of the multivariate normal density of vector(s) y given\nlocation row vector(s) mu and covariance matrix Sigma dropping constant additive\nterms\n;
multi_normal_lpdf;(row_vectors y | vectors mu, matrix Sigma);real;The log of the multivariate normal density of row vector(s) y given\nlocation vector(s) mu and covariance matrix Sigma\n;
multi_normal_lupdf;(row_vectors y | vectors mu, matrix Sigma);real;The log of the multivariate normal density of row vector(s) y given\nlocation vector(s) mu and covariance matrix Sigma dropping constant additive\nterms\n;
multi_normal_lpdf;(row_vectors y | row_vectors mu, matrix Sigma);real;The log of the multivariate normal density of row vector(s) y given\nlocation row vector(s) mu and covariance matrix Sigma\n;
multi_normal_lupdf;(row_vectors y | row_vectors mu, matrix Sigma);real;The log of the multivariate normal density of row vector(s) y given\nlocation row vector(s) mu and covariance matrix Sigma dropping constant additive\nterms\nAlthough there is a direct multi-normal RNG function, if more than one\nresult is required, it's much more efficient to Cholesky factor the\ncovariance matrix and call `multi_normal_cholesky_rng`  see section\n[multi-variate normal, cholesky parameterization](#multi-normal-cholesky-fun).\n;
multi_normal_rng;(vector mu, matrix Sigma);vector;Generate a multivariate normal variate with location mu and covariance\nmatrix Sigma may only be used in transformed data and generated quantities blocks\n;
multi_normal_rng;(row_vector mu, matrix Sigma);vector;Generate a multivariate normal variate with location mu and covariance\nmatrix Sigma may only be used in transformed data and generated quantities blocks\n;
multi_normal_rng;(vectors mu, matrix Sigma);vectors;Generate an array of multivariate normal variates with locations mu\nand covariance matrix Sigma may only be used in transformed data and generated\nquantities blocks\n;
multi_normal_rng;(row_vectors mu, matrix Sigma);vectors;Generate an array of multivariate normal variates with locations mu\nand covariance matrix Sigma may only be used in transformed data and generated\nquantities blocks\n;
multi_normal_prec;~;real;Increment target log probability density with `multi_normal_prec_lupdf(y | mu, Omega)`.;
multi_normal_prec_lpdf;(vectors y | vectors mu, matrix Omega);real;The log of the multivariate normal density of vector(s) y given\nlocation vector(s) mu and positive definite precision matrix Omega\n;
multi_normal_prec_lupdf;(vectors y | vectors mu, matrix Omega);real;The log of the multivariate normal density of vector(s) y given\nlocation vector(s) mu and positive definite precision matrix Omega\ndropping constant additive terms\n;
multi_normal_prec_lpdf;(vectors y | row_vectors mu, matrix Omega);real;The log of the multivariate normal density of vector(s) y given\nlocation row vector(s) mu and positive definite precision matrix Omega\n;
multi_normal_prec_lupdf;(vectors y | row_vectors mu, matrix Omega);real;The log of the multivariate normal density of vector(s) y given\nlocation row vector(s) mu and positive definite precision matrix Omega\ndropping constant additive terms\n;
multi_normal_prec_lpdf;(row_vectors y | vectors mu, matrix Omega);real;The log of the multivariate normal density of row vector(s) y given\nlocation vector(s) mu and positive definite precision matrix Omega\n;
multi_normal_prec_lupdf;(row_vectors y | vectors mu, matrix Omega);real;The log of the multivariate normal density of row vector(s) y given\nlocation vector(s) mu and positive definite precision matrix Omega\ndropping constant additive terms\n;
multi_normal_prec_lpdf;(row_vectors y | row_vectors mu, matrix Omega);real;The log of the multivariate normal density of row vector(s) y given\nlocation row vector(s) mu and positive definite precision matrix Omega\n;
multi_normal_prec_lupdf;(row_vectors y | row_vectors mu, matrix Omega);real;The log of the multivariate normal density of row vector(s) y given\nlocation row vector(s) mu and positive definite precision matrix Omega\ndropping constant additive terms\n;
multi_normal_cholesky;~;real;Increment target log probability density with `multi_normal_cholesky_lupdf(y | mu, L)`.;
multi_normal_cholesky_lpdf;(vectors y | vectors mu, matrix L);real;The log of the multivariate normal density of vector(s) y given\nlocation vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L\n;
multi_normal_cholesky_lupdf;(vectors y | vectors mu, matrix L);real;The log of the multivariate normal density of vector(s) y given\nlocation vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L dropping constant additive terms\n;
multi_normal_cholesky_lpdf;(vectors y | row_vectors mu, matrix L);real;The log of the multivariate normal density of vector(s) y given\nlocation row vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L\n;
multi_normal_cholesky_lupdf;(vectors y | row_vectors mu, matrix L);real;The log of the multivariate normal density of vector(s) y given\nlocation row vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L dropping constant additive terms\n;
multi_normal_cholesky_lpdf;(row_vectors y | vectors mu, matrix L);real;The log of the multivariate normal density of row vector(s) y given\nlocation vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L\n;
multi_normal_cholesky_lupdf;(row_vectors y | vectors mu, matrix L);real;The log of the multivariate normal density of row vector(s) y given\nlocation vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L dropping constant additive terms\n;
multi_normal_cholesky_lpdf;(row_vectors y | row_vectors mu, matrix L);real;The log of the multivariate normal density of row vector(s) y given\nlocation row vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L\n;
multi_normal_cholesky_lupdf;(row_vectors y | row_vectors mu, matrix L);real;The log of the multivariate normal density of row vector(s) y given\nlocation row vector(s) mu and lower-triangular Cholesky factor of the\ncovariance matrix L dropping constant additive terms\n;
multi_normal_cholesky_rng;(vector mu, matrix L);vector;Generate a multivariate normal variate with location mu and\nlower-triangular Cholesky factor of the covariance matrix L may only\nbe used in transformed data and generated quantities blocks\n;
multi_normal_cholesky_rng;(row_vector mu, matrix L);vector;Generate a multivariate normal variate with location mu and\nlower-triangular Cholesky factor of the covariance matrix L may only\nbe used in transformed data and generated quantities blocks\n;
multi_normal_cholesky_rng;(vectors mu, matrix L);vectors;Generate an array of multivariate normal variates with locations mu\nand lower-triangular Cholesky factor of the covariance matrix L may\nonly be used in transformed data and generated quantities blocks\n;
multi_normal_cholesky_rng;(row_vectors mu, matrix L);vectors;Generate an array of multivariate normal variates with locations mu\nand lower-triangular Cholesky factor of the covariance matrix L may\nonly be used in transformed data and generated quantities blocks\n;
multi_gp;~;real;Increment target log probability density with `multi_gp_lupdf(y | Sigma, w)`.;
multi_gp_lpdf;(matrix y | matrix Sigma, vector w);real;The log of the multivariate GP density of matrix y given kernel matrix\nSigma and inverses scales w\n;
multi_gp_lupdf;(matrix y | matrix Sigma, vector w);real;The log of the multivariate GP density of matrix y given kernel matrix\nSigma and inverses scales w dropping constant additive terms\n;
multi_gp_cholesky;~;real;Increment target log probability density with `multi_gp_cholesky_lupdf(y | L, w)`.;
multi_gp_cholesky_lpdf;(matrix y | matrix L, vector w);real;The log of the multivariate GP density of matrix y given\nlower-triangular Cholesky factor of the kernel matrix L and inverses\nscales w\n;
multi_gp_cholesky_lupdf;(matrix y | matrix L, vector w);real;The log of the multivariate GP density of matrix y given\nlower-triangular Cholesky factor of the kernel matrix L and inverses\nscales w dropping constant additive terms\n;
multi_student_t;~;real;Increment target log probability density with `multi_student_t_lupdf(y | nu, mu, Sigma)`.;
multi_student_t_lpdf;(vectors y | real nu, vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of vector(s) y given\ndegrees of freedom nu, location vector(s) mu, and scale matrix Sigma\n;
multi_student_t_lupdf;(vectors y | real nu, vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of vector(s) y given\ndegrees of freedom nu, location vector(s) mu, and scale matrix Sigma\ndropping constant additive terms\n;
multi_student_t_lpdf;(vectors y | real nu, row_vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of vector(s) y given\ndegrees of freedom nu, location row vector(s) mu, and scale matrix\nSigma\n;
multi_student_t_lupdf;(vectors y | real nu, row_vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of vector(s) y given\ndegrees of freedom nu, location row vector(s) mu, and scale matrix\nSigma dropping constant additive terms\n;
multi_student_t_lpdf;(row_vectors y | real nu, vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of row vector(s) y\ngiven degrees of freedom nu, location vector(s) mu, and scale matrix\nSigma\n;
multi_student_t_lupdf;(row_vectors y | real nu, vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of row vector(s) y\ngiven degrees of freedom nu, location vector(s) mu, and scale matrix\nSigma dropping constant additive terms\n;
multi_student_t_lpdf;(row_vectors y | real nu, row_vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of row vector(s) y\ngiven degrees of freedom nu, location row vector(s) mu, and scale\nmatrix Sigma\n;
multi_student_t_lupdf;(row_vectors y | real nu, row_vectors mu, matrix Sigma);real;The log of the multivariate Student-$t$ density of row vector(s) y\ngiven degrees of freedom nu, location row vector(s) mu, and scale\nmatrix Sigma dropping constant additive terms\n;
multi_student_t_rng;(real nu, vector mu, matrix Sigma);vector;Generate a multivariate Student-$t$ variate with degrees of freedom\nnu, location mu, and scale matrix Sigma may only be used in transformed data\nand generated quantities blocks\n;
multi_student_t_rng;(real nu, row_vector mu, matrix Sigma);vector;Generate a multivariate Student-$t$ variate with degrees of freedom\nnu, location mu, and scale matrix Sigma may only be used in transformed data\nand generated quantities blocks\n;
multi_student_t_rng;(real nu, vectors mu, matrix Sigma);vectors;Generate an array of multivariate Student-$t$ variates with degrees of\nfreedom nu, locations mu, and scale matrix Sigma may only be used in\ntransformed data and generated quantities blocks\n;
multi_student_t_rng;(real nu, row_vectors mu, matrix Sigma);vectors;Generate an array of multivariate Student-$t$ variates with degrees of\nfreedom nu, locations mu, and scale matrix Sigma may only be used in\ntransformed data andgenerated quantities blocks\n;
multi_student_t_cholesky;~;real;Increment target log probability density with `multi_student_t_cholesky_lupdf(y | nu, mu, L)`.;
multi_student_t_cholesky_lpdf;(vectors y | real nu, vectors mu, matrix L);real;The log of the multivariate Student-$t$ density of vector or array of\nvectors `y` given\ndegrees of freedom `nu`, location vector or array of vectors `mu`, and Cholesky factor of the scale matrix `L`.\nFor a definition of the arguments compatible with the `vectors` type,\nsee the [probability vectorization section](conventions_for_probability_functions.qmd#prob-vectorization).\n;
multi_student_t_cholesky_lupdf;(vectors y | real nu, vectors mu, matrix L);real;The log of the multivariate Student-$t$ density of vector or vector\narray `y` given\ndegrees of freedom `nu`, location vector or vector array `mu`, and Cholesky factor of the scale matrix `L`,\ndropping constant additive terms.  For a definition of arguments\ncompatible with the `vectors` type, see the [probability vectorization\nsection](conventions_for_probability_functions.qmd#prob-vectorization).\n;
multi_student_cholesky_t_rng;(real nu, vector mu, matrix L);vector;Generate a multivariate Student-$t$ variate with degrees of freedom\n`nu`, location `mu`, and Cholesky factor of the scale matrix `L` may only be used in transformed data\nand generated quantities blocks.\n;
multi_student_t_cholesky_rng;(real nu, array[] vector mu, matrix L);array[] vector;Generate a multivariate Student-$t$ variate with degrees of freedom\n`nu`, location array `mu`, and Cholesky factor of the scale matrix `L` may only be used in transformed data\nand generated quantities blocks.\n;
multi_student_t_cholesky_rng;(real nu, array[] row_vector mu, matrix L);array[] vector;Generate an array of multivariate Student-$t$ variate with degrees of freedom\n`nu`, location array `mu`, and Cholesky factor of the scale matrix `L` may only be used in transformed data\nand generated quantities blocks.\n;
gaussian_dlm_obs;~;real;Increment target log probability density with `gaussian_dlm_obs_lupdf(y | F, G, V, W, m0, C0)`.;
gaussian_dlm_obs_lpdf;(matrix y | matrix F, matrix G, matrix V, matrix W, vector m0, matrix C0);real;The log of the density of the Gaussian Dynamic Linear model with\nobservation matrix y in which rows are variables and columns are\nobservations, design matrix F, transition matrix G, observation\ncovariance matrix V, system covariance matrix W, and the initial state\nis distributed normal with mean m0 and covariance C0.\n;
gaussian_dlm_obs_lupdf;(matrix y | matrix F, matrix G, matrix V, matrix W, vector m0, matrix C0);real;The log of the density of the Gaussian Dynamic Linear model with\nobservation matrix y in which rows are variables and columns are\nobservations, design matrix F, transition matrix G, observation\ncovariance matrix V, system covariance matrix W, and the initial state\nis distributed normal with mean m0 and covariance C0. This function drops\nconstant additive terms.\n;
gaussian_dlm_obs_lpdf;(matrix y | matrix F, matrix G, vector V, matrix W, vector m0, matrix C0);real;The log of the density of the Gaussian Dynamic Linear model with\nobservation matrix y in which rows are variables and columns are\nobservations, design matrix F, transition matrix G, observation\ncovariance matrix with diagonal V, system covariance matrix W, and the\ninitial state is distributed normal with mean m0 and covariance C0.\n;
gaussian_dlm_obs_lupdf;(matrix y | matrix F, matrix G, vector V, matrix W, vector m0, matrix C0);real;The log of the density of the Gaussian Dynamic Linear model with\nobservation matrix y in which rows are variables and columns are\nobservations, design matrix F, transition matrix G, observation\ncovariance matrix with diagonal V, system covariance matrix W, and the\ninitial state is distributed normal with mean m0 and covariance C0.\nThis function drops constant additive terms.\n;
min;(array[] real x);real;The minimum value in x, or $+\infty$ if x is size 0.\n;
min;(array[] int x);int;The minimum value in x, or error if x is size 0.\n;
max;(array[] real x);real;The maximum value in x, or $-\infty$ if x is size 0.\n;
max;(array[] int x);int;The maximum value in x, or error if x is size 0.\n;
sum;(array[] int x);int;The sum of the elements in x, or 0 if the array is empty.\n;
sum;(array[] real x);real;The sum of the elements in x see definition above.\n;
sum;(array[] complex x);complex;The sum of the elements in x see definition above.\n;
prod;(array[] real x);real;The product of the elements in x, or 1 if x is size 0.\n;
prod;(array[] int x);real;The product of the elements in x,\n\begin{equation*}\n\text{product}(x) = \begin{cases}\n\prod_{n=1}^N x_n & \text{if} N > 0 \\[4pt] 1 & \text{if} N = 0\n\end{cases}\n\end{equation*}\n;
log_sum_exp;(array[] real x);real;The natural logarithm of the sum of the exponentials of the elements\nin x, or $-\infty$ if the array is empty.\n;
mean;(array[] real x);real;The sample mean of the elements in x. For an array $x$ of size $N >\n0$,\n\begin{equation*}\n\text{mean}(x) \ = \ \bar{x} \ = \ \frac{1}{N} \sum_{n=1}^N\nx_n.\n\end{equation*}\nIt is an error to the call the mean function with an array of\nsize $0$.\n;
variance;(array[] real x);real;The sample variance of the elements in x. For $N > 0$,\n\begin{equation*}\n\text{variance}(x) \ = \ \begin{cases} \frac{1}{N-1} \sum_{n=1}^N (x_n\n- \bar{x})^2 & \text{if } N > 1 \\[4pt] 0 & \text{if } N = 1\n\end{cases}\n\end{equation*}\nIt is an error to call the `variance` function with an\narray of size 0.\n;
sd;(array[] real x);real;The sample standard deviation of elements in x.\n\begin{equation*}\n\text{sd}(x) =\n\begin{cases} \sqrt{\, \text{variance}(x)} & \text{if } N > 1 \\[4pt]\n0 & \text{if } N = 0 \end{cases}\n\end{equation*} It is an error to call the `sd`\nfunction with an array of size 0.\n;
norm1;(vector x);real;The L1 norm of x, defined by\n\begin{equation*}\n\text{norm1}(x) \ = \ \textstyle \sum_{n=1}^N (|x_n|)\n\end{equation*}\nwhere `N` is the size of x.\n;
norm1;(row_vector x);real;The L1 norm of x\n;
norm1;(array[] real x);real;The L1 norm of x\n;
norm2;(vector x);real;The L2 norm of x, defined by\n\begin{equation*}\n\text{norm2}(x) \ = \ \sqrt{\textstyle \sum_{n=1}^N (x_n)^2}\n\end{equation*}\nwhere `N` is the size of x\n;
norm2;(row_vector x);real;The L2 norm of x\n;
norm2;(array[] real x);real;The L2 norm of x\n;
distance;(vector x, vector y);real;The Euclidean distance between x and y, defined by\n\begin{equation*}\n\text{distance}(x,y) \ = \ \sqrt{\textstyle \sum_{n=1}^N (x_n - y_n)^2}\n\end{equation*}\nwhere `N` is the size of x and y. It is an error to call\n`distance` with arguments of unequal size.\n;
distance;(vector x, row_vector y);real;The Euclidean distance between x and y\n;
distance;(row_vector x, vector y);real;The Euclidean distance between x and y\n;
distance;(row_vector x, row_vector y);real;The Euclidean distance between x and y\n;
squared_distance;(vector x, vector y);real;The squared Euclidean distance between x and y, defined by\n\begin{equation*}\n\mathrm{squared\_distance}(x,y) \ = \ \text{distance}(x,y)^2 \ = \ \textstyle \sum_{n=1}^N (x_n - y_n)^2,\n\end{equation*}\nwhere `N` is the size of x\nand y. It is an error to call `squared_distance` with arguments of\nunequal size.\n;
squared_distance;(vector x, row_vector y);real;The squared Euclidean distance between x and y\n;
squared_distance;(row_vector x, vector y);real;The squared Euclidean distance between x and y\n;
squared_distance;(row_vector x, row_vector y);real;The Euclidean distance between x and y\n;
quantile;(data array[] real x, data real p);real;The p-th quantile of x\n;
quantile;(data array[] real x, data array[] real p);array[] real;An array containing the quantiles of x given by the array of probabilities p\n;
dims;(T x);array[] int;Return an integer array containing the dimensions of x the type of\nthe argument T can be any Stan type with up to 8 array dimensions.\n;
num_elements;(array[] T x);int;Return the total number of elements in the array x including all\nelements in contained arrays, vectors, and matrices. T can be any\narray type. For example, if `x` is of type `array[4, 3] real` then\n`num_elements(x)` is 12, and if `y` is declared as `array[5] matrix[3, 4] y`,\nthen `size(y)` evaluates to 60.\n;
size;(array[] T x);int;Return the number of elements in the array x the type of the array T\ncan be any type, but the size is just the size of the top level array,\nnot the total number of elements contained. For example, if `x` is of\ntype `array[4, 3] real` then `size(x)` is 4.\n;
rep_array;(T x, int n);array[] T;Return the n array with every entry assigned to x.\n;
rep_array;(T x, int m, int n);array[,] T;Return the m by n array with every entry assigned to x.\n;
rep_array;(T x, int k, int m, int n);array[,,] T;Return the k by m by n array with every entry assigned to x.\nFor example, `rep_array(1.0,5)` produces a real array (type `array[] real`)\nof size 5 with all values set to 1.0.  On the other hand,\n`rep_array(1,5)` produces an integer array (type `array[] int`) of size 5\nwith all values set to 1.  This distinction is important because it is\nnot possible to assign an integer array to a real array.  For example,\nthe following example contrasts legal with illegal array creation and\nassignment\n```stan\n array[5] real y\n array[5] int x\n x = rep_array(1, 5)     // ok\n y = rep_array(1.0, 5)   // ok\n x = rep_array(1.0, 5)   // illegal\n y = rep_array(1, 5)     // illegal\n x = y                  // illegal\n y = x                  // illegal\n```\nIf the value being repeated `v` is a vector (i.e., `T` is `vector`),\nthen `rep_array(v, 27)` is a size 27 array consisting of 27 copies of\nthe vector `v`.\n```stan\n vector[5] v\n array[3] vector[5] a\n a = rep_array(v, 3)  // fill a with copies of v\n a[2, 4] = 9.0        // v[4], a[1, 4], a[3, 4] unchanged\n```\nIf the type T of x is itself an array type, then the result will be an\narray with one, two, or three added dimensions, depending on which of\nthe `rep_array` functions is called.  For instance, consider the\nfollowing legal code snippet.\n```stan\n array[5, 6] real a\n array[3, 4, 5, 6] real b\n b = rep_array(a, 3, 4) //  make (3 x 4) copies of a\n b[1, 1, 1, 1] = 27.9    //  a[1, 1] unchanged\n```\nAfter the assignment to `b`, the value for `b[j, k, m, n]` is equal to\n`a[m, n]` where it is defined, for `j` in `1:3`, `k` in `1:4`, `m` in\n`1:5`, and `n` in `1:6`.\n;
append_array;(T x, T y);T;Return the concatenation of two arrays in the order of the arguments.\nT must be an N-dimensional array of any Stan type (with a maximum N of\n7). All dimensions but the first must match.\nFor example, the following code appends two three dimensional arrays\nof matrices together. Note that all dimensions except the first match.\nAny mismatches will cause an error to be thrown.\n```stan\n array[2, 1, 7] matrix[4, 6] x1\n array[3, 1, 7] matrix[4, 6] x2\n array[5, 1, 7] matrix[4, 6] x3\n x3 = append_array(x1, x2)\n```\n;
sort_asc;(array[] real v);array[] real;Sort the elements of v in ascending order\n;
sort_asc;(array[] int v);array[] int;Sort the elements of v in ascending order\n;
sort_desc;(array[] real v);array[] real;Sort the elements of v in descending order\n;
sort_desc;(array[] int v);array[] int;Sort the elements of v in descending order\n;
sort_indices_asc;(array[] real v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in ascending order.\n;
sort_indices_asc;(array[] int v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in ascending order.\n;
sort_indices_desc;(array[] real v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in descending order.\n;
sort_indices_desc;(array[] int v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in descending order.\n;
rank;(array[] real v, int s);int;Number of components of v less than v[s]\n;
rank;(array[] int v, int s);int;Number of components of v less than v[s]\n;
reverse;(array[] T v);array[] T;Return a new array containing the elements of the argument in reverse order.\n;
to_complex;();complex;Return complex number with real part 0.0 and imaginary part 0.0.\n;
to_complex;(real re);complex;Return complex number with real part `re` and imaginary part 0.0.\n;
to_complex;(real re, real im);complex;Return complex number with real part `re` and imaginary part `im`.\n;
to_complex;(T1 re, T2 im);Z;Vectorized implementation of the `to_complex` function.\n`T1` and `T2` can either be real containers of the same size, or a real\ncontainer and a real, in which case the real value is used for the corresponding\ncomponent in all elements of the output.\n;
get_real;(complex z);real;Return the real part of the complex number `z`.\n;
get_imag;(complex z);real;Return the imaginary part of the complex number `z`.\n;
operator+;(complex z);complex;Return the complex argument `z`, \begin{equation*} +z = z. \end{equation*}\n;
operator-;(complex z);complex;Return the negation of the complex argument `z`, which for $z = x + yi$ is\n\begin{equation*} -z = -x - yi. \end{equation*}\n;
operator-;(T x);T;Vectorized version of `operator-`. If `T x` is a (possibly nested) array of\ncomplex numbers, `-x` is the same shape array where each individual value is negated.\n;
operator+;(complex x, complex y);complex;Return the sum of x and y, \begin{equation*} (x + y) = \text{operator+}(x, y) = x + y. \end{equation*}\n;
operator-;(complex x, complex y);complex;Return the difference between x and y, \begin{equation*} (x - y) =\n\text{operator-}(x, y) = x - y. \end{equation*}\n;
operator*;(complex x, complex y);complex;Return the product of x and y, \begin{equation*} (x \, * \, y) = \text{operator*}(x, y) = x\n\times y. \end{equation*}\n;
operator/;(complex x, complex y);complex;Return the quotient of x and y, \begin{equation*} (x / y) = \text{operator/}(x,y) =\n\frac{x}{y} \end{equation*}\n;
operator^;(complex x, complex y);complex;Return x raised to the power of y,\n\begin{equation*}\n(x^\mathrm{\wedge}y)= \text{operator}^\mathrm{\wedge}(x,y)\n= \textrm{exp}(y \, \log(x)).\n\end{equation*}\n;
operator==;(complex x, complex y);int;Return 1 if x is equal to y and 0 otherwise,\n\begin{equation*}\n(x \,\text{==}\, y)\n\ = \ \text{operator==}(x,y)\n\ = \ \begin{cases} 1 & \text{if $x = y$}, \ \text{and} \\ 0 & \text{otherwise.}\n\end{cases}\n\end{equation*}\n;
operator!=;(complex x, complex y);int;Return 1 if x is not equal to y and 0 otherwise,\n\begin{equation*}\n(x \,\text{!=}\, y)\n\ = \ \text{operator!=}(x,y)\n\ = \ \begin{cases} 1 & \text{if $x \neq y$}, \ \text{and} \\ 0 &\n\text{otherwise.} \end{cases}\n\end{equation*}\n;
operator=;(complex x, complex y);void;`y = x` assigns a (copy of) the value of `y` to `x`.\n;
operator+=;(complex x, complex y);void;`x += y` is equivalent to `x = x + y`.\n;
operator-=;(complex x, complex y);void;`x -= y` is equivalent to `x = x - y`.\n;
operator*=;(complex x, complex y);void;`x *= y` is equivalent to `x = x * y`.\n;
operator/=;(complex x, complex y);void;`x /= y` is equivalent to `x = x / y`.\n;
abs;(complex z);real;Return the absolute value of z, also known as the modulus or\nmagnitude, which for $z = x + yi$ is\n\begin{equation*}\n\textrm{abs}(z) = \sqrt{x^2 + y^2}.\n\end{equation*}\nThis function works elementwise over containers, returning the same shape and\nkind of the input container but holding reals. For example, a\n`complex_vector[n]` input will return a `vector[n]` output, with each element\ntransformed by the above equation.\n;
arg;(complex z);real;Return the phase angle (in radians) of z, which for $z = x + yi$ is\n\begin{equation*}\n\textrm{arg}(z) = \textrm{atan2}(y, x) = \textrm{atan}(y / x).\n\end{equation*}\n;
norm;(complex z);real;Return the Euclidean norm of z, which is its absolute value squared,\nand which for $z = x + yi$ is\n\begin{equation*}\n\textrm{norm}(z) = \textrm{abs}^2(z) = x^2 + y^2.\n\end{equation*}\n;
conj;(complex z);complex;Return the complex conjugate of z, which negates the imaginary component,\nso that if $z = x + yi$,\n\begin{equation*}\n\textrm{conj}(z) = x - yi.\n\end{equation*}\n;
conj;(Z z);Z;Vectorized version of `conj`. This will apply the `conj` function\nto each element of a complex array, vector, or matrix.\n;
proj;(complex z);complex;Return the projection of `z` onto the Riemann sphere, which for $z = x\n+ yi$ is\n\begin{equation*}\n\textrm{proj}(z)\n= \begin{cases}\n    z & \textrm{if} \ z \ \textrm{is finite, and} \\\n    0 + \textrm{sign}(y)i & \textrm{otherwise,}\n\end{cases}\n\end{equation*}\nwhere $\textrm{sign}(y)$ is -1 if $y$ is negative and 1 otherwise.\n;
polar;(real r, real theta);complex;Return the complex number with magnitude (absolute value) `r` and\nphase angle `theta`.\n;
exp;(complex z);complex;Return the complex natural exponential of `z`, which for $z = x + yi$\nis\n\begin{equation*}\n\exp z = \exp(x) \textrm{cis}(y) = \exp(x) (\cos(y) + i \sin(y)).\n\end{equation*}\n;
log;(complex z);complex;Return the complex natural logarithm of `z`, which for $z = \textrm{polar}(r,\n\theta)$ is\n\begin{equation*}\n\log z = \log r + \theta i.\n\end{equation*}\n;
log10;(complex z);complex;Return the complex common logarithm of `z`,\n\begin{equation*}\n\log_{10} z = \frac{\log z}{\log 10}.\n\end{equation*}\n;
pow;(complex x, complex y);complex;Return x raised to the power of y,\n\begin{equation*}\n\text{pow}(x,y) = \textrm{exp}(y \, \log(x)).\n\end{equation*}\n;
pow;(T1 x, T2 y);Z;Vectorized implementation of the `pow` function\n;
sqrt;(complex x);complex;Return the complex square root of x with branch cut along the negative\nreal axis.  For finite inputs, the result will be in the right\nhalf-plane.\n;
cos;(complex z);complex;Return the complex cosine of z, which is\n\begin{equation*}\n\cos(z)\n= \textrm{cosh}(z \, i)\n= \frac{\displaystyle \exp(z \, i) + \exp(-z \, i)}\n       {\displaystyle 2}.\n\end{equation*}\n;
sin;(complex z);complex;Return the complex sine of z,\n\begin{equation*}\n\sin(z)\n= -\textrm{sinh}(z \, i) \, i\n= \frac{\displaystyle \exp(z \, i) - \exp(-z \, i)}\n       {\displaystyle 2 \, i}.\n\end{equation*}\n;
tan;(complex z);complex;Return the complex tangent of z,\n\begin{equation*}\n\tan(z)\n= -\textrm{tanh}(z \, i) \, i\n= \frac{(\exp(-z \, i) - \exp(z \, i)) \, i}\n       {\exp(-z \, i) + \exp(z \, i)}.\n\end{equation*}\n;
acos;(complex z);complex;Return the complex arc (inverse) cosine of z,\n\begin{equation*}\n\textrm{acos}(z)\n= \frac{1}{2} \pi + \log (z \, i + \sqrt{1 - z^2}) \, i.\n\end{equation*}\n;
asin;(complex z);complex;Return the complex arc (inverse) sine of z,\n\begin{equation*}\n\text{asin}(z)\n= -\log(z \, i + \sqrt{1 - z^2}) \, i.\n\end{equation*}\n;
atan;(complex z);complex;Return the complex arc (inverse) tangent of z,\n\begin{equation*}\n\text{atan}(z)\n= - \frac{1}{2} (\log(1 - z \, i) - \log(1 + z \, i)) \, i.\n\end{equation*}\n;
cosh;(complex z);complex;Return the complex hyperbolic cosine of z,\n\begin{equation*}\n\textrm{cosh}(z)\n= \frac{\exp(z) + \exp(-z)}\n       {2}.\n\end{equation*}\n;
sinh;(complex z);complex;Return the complex hyperbolic sine of z,\n\begin{equation*}\n\textrm{sinh}(z)\n= \frac{\displaystyle \exp(z) - \exp(-z)}\n       {\displaystyle 2}.\n\end{equation*}\n;
tanh;(complex z);complex;Return the complex hyperbolic tangent of z,\n\begin{equation*}\n\textrm{tanh}(z)\n\ = \ \frac{\textrm{sinh}(z)}\n           {\textrm{cosh}(z)}\n\ = \ \frac{\displaystyle \exp(z) - \exp(-z)}\n           {\displaystyle \exp(z) + \exp(-z)}.\n\end{equation*}\n;
acosh;(complex z);complex;Return the complex hyperbolic arc (inverse) cosine of z,\n\begin{equation*}\n\textrm{acosh}(z)\n= \log(z + \sqrt{(z + 1)(z - 1)}).\n\end{equation*}\n;
asinh;(complex z);complex;Return the complex hyperbolic arc (inverse) sine of z,\n\begin{equation*}\n\textrm{asinh}(z)\n= \log(z + \sqrt{1 + z^2}).\n\end{equation*}\n;
atanh;(complex z);complex;Return the complex hyperbolic arc (inverse) tangent of z,\n\begin{equation*}\n\textrm{atanh}(z)\n= \frac{\log(1 + z) - \log(1 - z)}\n       {2}.\n\end{equation*}\n;
ode_rk45;(function ode, vector initial_state, real initial_time, array[] real times, ...);array[] vector;Solves the ODE system for the times provided using the Dormand-Prince\nalgorithm, a 4th/5th order Runge-Kutta method.\n;
ode_rk45_tol;(function ode, vector initial_state, real initial_time, array[] real times, data real rel_tol, data real abs_tol, int max_num_steps, ...);array[] vector;Solves the ODE system for the times provided using the Dormand-Prince\nalgorithm, a 4th/5th order Runge-Kutta method with additional control\nparameters for the solver.\n;
ode_ckrk;(function ode, vector initial_state, real initial_time, array[] real times, ...);array[] vector;Solves the ODE system for the times provided using the Cash-Karp\nalgorithm, a 4th/5th order explicit Runge-Kutta method.\n;
ode_ckrk_tol;(function ode, vector initial_state, real initial_time, array[] real times, data real rel_tol, data real abs_tol, int max_num_steps, ...);array[] vector;Solves the ODE system for the times provided using the Cash-Karp\nalgorithm, a 4th/5th order explicit Runge-Kutta method with additional control\nparameters for the solver.\n;
ode_adams;(function ode, vector initial_state, real initial_time, array[] real times, ...);array[] vector;Solves the ODE system for the times provided using the Adams-Moulton method.\n;
ode_adams_tol;(function ode, vector initial_state, real initial_time, array[] real times, data real rel_tol, data real abs_tol, int max_num_steps, ...);array[] vector;Solves the ODE system for the times provided using the Adams-Moulton\nmethod with additional control parameters for the solver.\n;
ode_bdf;(function ode, vector initial_state, real initial_time, array[] real times, ...);array[] vector;Solves the ODE system for the times provided using the backward differentiation\nformula (BDF) method.\n;
ode_bdf_tol;(function ode, vector initial_state, real initial_time, array[] real times, data real rel_tol, data real abs_tol, int max_num_steps, ...);array[] vector;Solves the ODE system for the times provided using the backward differentiation\nformula (BDF) method with additional control parameters for the solver.\n;
ode_adjoint_tol_ctl;(function ode, vector initial_state, real initial_time, array[] real times, data real rel_tol_forward, data vector abs_tol_forward, data real rel_tol_backward, data vector abs_tol_backward, data real rel_tol_quadrature, data real abs_tol_qudrature, int max_num_steps, int num_steps_between_checkpoints, int interpolation_polynomial, int solver_forward, int solver_backward,...);array[] vector;Solves the ODE system for the times provided using the adjoint ODE solver method\nfrom CVODES. The adjoint ODE solver requires a checkpointed forward in time ODE\nintegration, a backwards in time integration that makes uses of an interpolated\nversion of the forward solution, and the solution of a quadrature problem (the\nnumber of which depends on the number of parameters passed to the solve). The\ntolerances and numeric methods used for the forward solve, backward solve,\nquadratures, and interpolation can all be configured.\n;
dae;(function residual, vector initial_state, vector initial_state_derivative, data real initial_time, data array[] real times, ...);array[] vector;Solves the DAE system using the backward differentiation formula (BDF)\nmethod [@serban_user:2021].\n;
dae_tol;(function residual, vector initial_state, vector initial_state_derivative, data real initial_time, data array[] real times, data real rel_tol, data real abs_tol, int max_num_steps, ...);array[] vector;Solves the DAE system for the times provided using the backward differentiation formula (BDF) method with additional control\nparameters for the solver.\n;
integrate_1d;(function integrand, real a, real b, array[] real theta, array[] real x_r, array[] int x_i);real;Integrates the integrand from a to b.\n;
integrate_1d;(function integrand, real a, real b, array[] real theta, array[] real x_r, array[] int x_i), real relative_tolerance);real;Integrates the integrand from a to b with the given relative tolerance.\n;
reduce_sum;(F f, array[] T x, int grainsize, T1 s1, T2 s2, ...);real;Returns the equivalent of `f(x, 1, size(x), s1, s2, ...)`, but computes\nthe result in parallel by breaking the array `x` into independent\npartial sums. `s1, s2, ...` are shared between all terms in the sum.\n* *`f`*: function literal referring to a function specifying the\npartial sum operation. Refer to the [partial sum function](#functions-partial-sum).\n* *`x`*: array of `T`, one for each term of the reduction, `T` can be any type,\n* *`grainsize`*: For `reduce_sum`, `grainsize` is the recommended size of the partial sum (`grainsize = 1` means pick totally automatically). For `reduce_sum_static`, `grainsize` determines the maximum size of the partial sums, type `int`,\n* *`s1`*: first (optional) shared argument, type `T1`, where `T1` can be any type\n* *`s2`*: second (optional) shared argument, type `T2`, where `T2` can be any type,\n* *`...`*: remainder of shared arguments, each of which can be any type.\n;
map_rect;(F f, vector phi, array[] vector theta, data array[,] real x_r, data array[,] int x_i);vector;Return the concatenation of the results of applying the function f, of\ntype `(vector, vector, array[] real, array[] int):vector` elementwise, i.e.,\n`f(phi, theta[n], x_r[n], x_i[n])` for each `n` in `1:N`, where `N` is\nthe size of the parallel arrays of job-specific/local parameters\n`theta`, real data `x_r`, and integer data `x_r`. The shared/global\nparameters `phi` are passed to each invocation of `f`.\n;
lognormal;~;real;Increment target log probability density with `lognormal_lupdf(y | mu, sigma)`.;
lognormal_lpdf;(reals y | reals mu, reals sigma);real;The log of the lognormal density of y given location mu and scale\nsigma\n;
lognormal_lupdf;(reals y | reals mu, reals sigma);real;The log of the lognormal density of y given location mu and scale\nsigma dropping constant additive terms\n;
lognormal_cdf;(reals y | reals mu, reals sigma);real;The cumulative lognormal distribution function of y given location mu\nand scale sigma\n;
lognormal_lcdf;(reals y | reals mu, reals sigma);real;The log of the lognormal cumulative distribution function of y given\nlocation mu and scale sigma\n;
lognormal_lccdf;(reals y | reals mu, reals sigma);real;The log of the lognormal complementary cumulative distribution\nfunction of y given location mu and scale sigma\n;
lognormal_rng;(reals mu, reals sigma);R;Generate a lognormal variate with location mu and scale sigma may\nonly be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
chi_square;~;real;Increment target log probability density with `chi_square_lupdf(y | nu)`.;
chi_square_lpdf;(reals y | reals nu);real;The log of the Chi-square density of y given degrees of freedom nu\n;
chi_square_lupdf;(reals y | reals nu);real;The log of the Chi-square density of y given degrees of freedom nu\ndropping constant additive terms\n;
chi_square_cdf;(reals y | reals nu);real;The Chi-square cumulative distribution function of y given degrees of\nfreedom nu\n;
chi_square_lcdf;(reals y | reals nu);real;The log of the Chi-square cumulative distribution function of y given\ndegrees of freedom nu\n;
chi_square_lccdf;(reals y | reals nu);real;The log of the complementary Chi-square cumulative distribution\nfunction of y given degrees of freedom nu\n;
chi_square_rng;(reals nu);R;Generate a Chi-square variate with degrees of freedom nu may only be\nused in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
inv_chi_square;~;real;Increment target log probability density with `inv_chi_square_lupdf(y | nu)`.;
inv_chi_square_lpdf;(reals y | reals nu);real;The log of the inverse Chi-square density of y given degrees of\nfreedom nu\n;
inv_chi_square_lupdf;(reals y | reals nu);real;The log of the inverse Chi-square density of y given degrees of\nfreedom nu dropping constant additive terms\n;
inv_chi_square_cdf;(reals y | reals nu);real;The inverse Chi-squared cumulative distribution function of y given\ndegrees of freedom nu\n;
inv_chi_square_lcdf;(reals y | reals nu);real;The log of the inverse Chi-squared cumulative distribution function of\ny given degrees of freedom nu\n;
inv_chi_square_lccdf;(reals y | reals nu);real;The log of the inverse Chi-squared complementary cumulative\ndistribution function of y given degrees of freedom nu\n;
inv_chi_square_rng;(reals nu);R;Generate an inverse Chi-squared variate with degrees of freedom nu\nmay only be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
scaled_inv_chi_square;~;real;Increment target log probability density with `scaled_inv_chi_square_lupdf(y | nu, sigma)`.;
scaled_inv_chi_square_lpdf;(reals y | reals nu, reals sigma);real;The log of the scaled inverse Chi-square density of y given degrees of\nfreedom nu and scale sigma\n;
scaled_inv_chi_square_lupdf;(reals y | reals nu, reals sigma);real;The log of the scaled inverse Chi-square density of y given degrees of\nfreedom nu and scale sigma dropping constant additive terms\n;
scaled_inv_chi_square_cdf;(reals y | reals nu, reals sigma);real;The scaled inverse Chi-square cumulative distribution function of y\ngiven degrees of freedom nu and scale sigma\n;
scaled_inv_chi_square_lcdf;(reals y | reals nu, reals sigma);real;The log of the scaled inverse Chi-square cumulative distribution\nfunction of y given degrees of freedom nu and scale sigma\n;
scaled_inv_chi_square_lccdf;(reals y | reals nu, reals sigma);real;The log of the scaled inverse Chi-square complementary cumulative\ndistribution function of y given degrees of freedom nu and scale sigma\n;
scaled_inv_chi_square_rng;(reals nu, reals sigma);R;Generate a scaled inverse Chi-squared variate with degrees of freedom\nnu and scale sigma may only be used in transformed data and generated\nquantities blocks. For a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
exponential;~;real;Increment target log probability density with `exponential_lupdf(y | beta)`.;
exponential_lpdf;(reals y | reals beta);real;The log of the exponential density of y given inverse scale beta\n;
exponential_lupdf;(reals y | reals beta);real;The log of the exponential density of y given inverse scale beta\ndropping constant additive terms\n;
exponential_cdf;(reals y | reals beta);real;The exponential cumulative distribution function of y given inverse\nscale beta\n;
exponential_lcdf;(reals y | reals beta);real;The log of the exponential cumulative distribution function of y given\ninverse scale beta\n;
exponential_lccdf;(reals y | reals beta);real;The log of the exponential complementary cumulative distribution\nfunction of y given inverse scale beta\n;
exponential_rng;(reals beta);R;Generate an exponential variate with inverse scale beta may only be\nused in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
gamma;~;real;Increment target log probability density with `gamma_lupdf(y | alpha, beta)`.;
gamma_lpdf;(reals y | reals alpha, reals beta);real;The log of the gamma density of y given shape alpha and inverse scale\nbeta\n;
gamma_lupdf;(reals y | reals alpha, reals beta);real;The log of the gamma density of y given shape alpha and inverse scale\nbeta dropping constant additive terms\n;
gamma_cdf;(reals y | reals alpha, reals beta);real;The cumulative gamma distribution function of y given shape alpha and\ninverse scale beta\n;
gamma_lcdf;(reals y | reals alpha, reals beta);real;The log of the cumulative gamma distribution function of y given shape\nalpha and inverse scale beta\n;
gamma_lccdf;(reals y | reals alpha, reals beta);real;The log of the complementary cumulative gamma distribution function of\ny given shape alpha and inverse scale beta\n;
gamma_rng;(reals alpha, reals beta);R;Generate a gamma variate with shape alpha and inverse scale beta may\nonly be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
inv_gamma;~;real;Increment target log probability density with `inv_gamma_lupdf(y | alpha, beta)`.;
inv_gamma_lpdf;(reals y | reals alpha, reals beta);real;The log of the inverse gamma density of y given shape alpha and scale\nbeta\n;
inv_gamma_lupdf;(reals y | reals alpha, reals beta);real;The log of the inverse gamma density of y given shape alpha and scale\nbeta dropping constant additive terms\n;
inv_gamma_cdf;(reals y | reals alpha, reals beta);real;The inverse gamma cumulative distribution function of y given shape\nalpha and scale beta\n;
inv_gamma_lcdf;(reals y | reals alpha, reals beta);real;The log of the inverse gamma cumulative distribution function of y\ngiven shape alpha and scale beta\n;
inv_gamma_lccdf;(reals y | reals alpha, reals beta);real;The log of the inverse gamma complementary cumulative distribution\nfunction of y given shape alpha and scale beta\n;
inv_gamma_rng;(reals alpha, reals beta);R;Generate an inverse gamma variate with shape alpha and scale beta may\nonly be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
weibull;~;real;Increment target log probability density with `weibull_lupdf(y | alpha, sigma)`.;
weibull_lpdf;(reals y | reals alpha, reals sigma);real;The log of the Weibull density of y given shape alpha and scale sigma\n;
weibull_lupdf;(reals y | reals alpha, reals sigma);real;The log of the Weibull density of y given shape alpha and scale sigma\ndropping constant additive terms\n;
weibull_cdf;(reals y | reals alpha, reals sigma);real;The Weibull cumulative distribution function of y given shape alpha\nand scale sigma\n;
weibull_lcdf;(reals y | reals alpha, reals sigma);real;The log of the Weibull cumulative distribution function of y given\nshape alpha and scale sigma\n;
weibull_lccdf;(reals y | reals alpha, reals sigma);real;The log of the Weibull complementary cumulative distribution function\nof y given shape alpha and scale sigma\n;
weibull_rng;(reals alpha, reals sigma);R;Generate a weibull variate with shape alpha and scale sigma may only\nbe used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
frechet;~;real;Increment target log probability density with `frechet_lupdf(y | alpha, sigma)`.;
frechet_lpdf;(reals y | reals alpha, reals sigma);real;The log of the Frechet density of y given shape alpha and scale sigma\n;
frechet_lupdf;(reals y | reals alpha, reals sigma);real;The log of the Frechet density of y given shape alpha and scale sigma\ndropping constant additive terms\n;
frechet_cdf;(reals y | reals alpha, reals sigma);real;The Frechet cumulative distribution function of y given shape alpha\nand scale sigma\n;
frechet_lcdf;(reals y | reals alpha, reals sigma);real;The log of the Frechet cumulative distribution function of y given\nshape alpha and scale sigma\n;
frechet_lccdf;(reals y | reals alpha, reals sigma);real;The log of the Frechet complementary cumulative distribution function\nof y given shape alpha and scale sigma\n;
frechet_rng;(reals alpha, reals sigma);R;Generate a Frechet variate with shape alpha and scale sigma may only\nbe used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
rayleigh;~;real;Increment target log probability density with `rayleigh_lupdf(y | sigma)`.;
rayleigh_lpdf;(reals y | reals sigma);real;The log of the Rayleigh density of y given scale sigma\n;
rayleigh_lupdf;(reals y | reals sigma);real;The log of the Rayleigh density of y given scale sigma\ndropping constant additive terms\n;
rayleigh_cdf;(real y | real sigma);real;The Rayleigh cumulative distribution of y given scale sigma\n;
rayleigh_lcdf;(real y | real sigma);real;The log of the Rayleigh cumulative distribution of y given scale sigma\n;
rayleigh_lccdf;(real y | real sigma);real;The log of the Rayleigh complementary cumulative distribution of y\ngiven scale sigma\n;
rayleigh_rng;(reals sigma);R;Generate a Rayleigh variate with scale sigma may only be used in\ngenerated quantities block. For a description of argument and return\ntypes, see section [vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
loglogistic;~;real;{{< since 2.29 >}};
loglogistic_lpdf;(reals y | reals alpha, reals beta);real;The log of the log-logistic density of y given scale alpha and shape beta\n;
loglogistic_cdf;(reals y | reals alpha, reals beta);real;The log-logistic cumulative distribution function of y given scale alpha and shape beta\n;
loglogistic_rng;(reals mu, reals sigma);R;Generate a log-logistic variate with scale alpha and shape beta may only\nbe used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
von_mises;~;real;Increment target log probability density with `von_mises_lupdf(y | mu, kappa)`.;
von_mises_lpdf;(reals y | reals mu, reals kappa);real;The log of the von mises density of y given location mu and scale\nkappa.\n;
von_mises_lupdf;(reals y | reals mu, reals kappa);real;The log of the von mises density of y given location mu and scale\nkappa dropping constant additive terms.\n;
von_mises_cdf;(reals y | reals mu, reals kappa);real;The von mises cumulative distribution function of y given location mu and scale\nkappa.\n;
von_mises_lcdf;(reals y | reals mu, reals kappa);real;The log of the von mises cumulative distribution function of y given location mu and scale\nkappa.\n;
von_mises_lccdf;(reals y | reals mu, reals kappa);real;The log of the von mises complementary cumulative distribution function of y given location mu and scale\nkappa.\n;
von_mises_rng;(reals mu, reals kappa);R;Generate a Von Mises variate with location mu and scale kappa (i.e.\nreturns values in the interval $[(\mu \mod 2\pi)-\pi,(\mu \mod\n2\pi)+\pi]$) may only be used in transformed data and generated quantities\nblocks. For a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
operator+;(int x, int y);int;The sum of the addends x and y \begin{equation*} \text{operator+}(x,y) = (x + y) \end{equation*}\n;
operator-;(int x, int y);int;The difference between the minuend x and subtrahend y \begin{equation*}\n\text{operator-}(x,y) = (x - y) \end{equation*}\n;
operator*;(int x, int y);int;The product of the factors x and y \begin{equation*} \text{operator*}(x,y) = (x\n\times y) \end{equation*}\n;
operator/;(int x, int y);int;The integer quotient of the dividend x and divisor y \begin{equation*}\n\text{operator/}(x,y) = \begin{cases} \lfloor x / y \rfloor & \text{if\n} x / y \geq 0 \\ - \lfloor \text{floor}(-x / y) \rfloor & \text{if }\nx / y < 0. \end{cases} \end{equation*}\n**deprecated** - use `operator%/%` instead.\n;
operator%/%;(int x, int y);int;The integer quotient of the dividend x and divisor y \begin{equation*}\n\text{operator\%/\%}(x,y) = \begin{cases} \lfloor x / y \rfloor & \text{if\n} x / y \geq 0 \\ - \lfloor \text{floor}(-x / y) \rfloor & \text{if }\nx / y < 0. \end{cases} \end{equation*}\n;
operator%;(int x, int y);int;x modulo y, which is the positive remainder after dividing x by y. If\nboth x and y are non-negative, so is the result otherwise, the sign\nof the result is platform dependent. \begin{equation*} \mathrm{operator\%}(x, y) \ =\n\ x \ \text{mod} \ y \ = \ x - y * \lfloor x / y \rfloor \end{equation*}\n;
operator-;(int x);int;The negation of the subtrahend x \begin{equation*} \text{operator-}(x) = -x \end{equation*}\n;
operator-;(T x);T;Vectorized version of `operator-`. If `T x` is a (possibly nested) array of\nintegers, `-x` is the same shape array where each individual integer is negated.\n;
operator+;(int x);int;This is a no-op. \begin{equation*} \text{operator+}(x) = x \end{equation*}\n;
abs;(T x);T;The absolute value of x.\nThis function works elementwise over containers such as vectors.\nGiven a type `T` which is `int`, or an array of `int`s, `abs` returns the same\ntype where each element has had its absolute value taken.\n;
int_step;(int x);int;;
int_step;(real x);int;Return the step function of x as an integer, \begin{equation*} \mathrm{int\_step}(x)\n= \begin{cases} 1 & \text{if } x > 0 \\ 0 & \text{if } x \leq 0 \text{\nor } x \text{ is } NaN \end{cases} \end{equation*} _**Warning:**_ `int_step(0)` and\n`int_step(NaN)` return 0 whereas `step(0)` and `step(NaN)` return 1.\nSee the warning in section [step functions](real-valued_basic_functions.qmd#step-functions) about the dangers of\nstep functions applied to anything other than data.\n;
min;(int x, int y);int;Return the minimum of x and y. \begin{equation*} \text{min}(x, y) = \begin{cases} x &\n\text{if } x < y\\ y & \text{otherwise} \end{cases} \end{equation*}\n;
max;(int x, int y);int;Return the maximum of x and y. \begin{equation*} \text{max}(x, y) = \begin{cases} x &\n\text{if } x > y\\ y & \text{otherwise} \end{cases} \end{equation*}\n;
size;(int x);int;;
size;(real x);int;Return the size of `x` which for scalar-valued `x` is 1\n;
to_int;(data real x);int;The vectorized version of `to_int`. This function accepts a (possibly nested)\narray of reals and returns an array of the same shape where each element has\nbeen truncated to an integer.\n;
uniform;~;real;Increment target log probability density with `uniform_lupdf(y | alpha, beta)`.;
uniform_lpdf;(reals y | reals alpha, reals beta);real;The log of the uniform density of y given lower bound alpha and upper\nbound beta\n;
uniform_lupdf;(reals y | reals alpha, reals beta);real;The log of the uniform density of y given lower bound alpha and upper\nbound beta dropping constant additive terms\n;
uniform_cdf;(reals y | reals alpha, reals beta);real;The uniform cumulative distribution function of y given lower bound\nalpha and upper bound beta\n;
uniform_lcdf;(reals y | reals alpha, reals beta);real;The log of the uniform cumulative distribution function of y given\nlower bound alpha and upper bound beta\n;
uniform_lccdf;(reals y | reals alpha, reals beta);real;The log of the uniform complementary cumulative distribution function\nof y given lower bound alpha and upper bound beta\n;
uniform_rng;(reals alpha, reals beta);R;Generate a uniform variate with lower bound alpha and upper bound\nbeta may only be used in transformed data and generated quantities blocks. For a\ndescription of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
integrate_ode_rk45;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i);array[,] real;\index{{\tt \bfseries integrate\_ode\_rk45 }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, array[] real x\_r, array[] int x\_i): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the Dormand-Prince\nalgorithm, a 4th/5th order Runge-Kutta method.\n;
integrate_ode_rk45;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i, real rel_tol, real abs_tol, int max_num_steps);array[,] real;\index{{\tt \bfseries integrate\_ode\_rk45 }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, array[] real x\_r, array[] int x\_i, real rel\_tol, real abs\_tol, int max\_num\_steps): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the Dormand-Prince\nalgorithm, a 4th/5th order Runge-Kutta method with additional control\nparameters for the solver.\n;
integrate_ode;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i);array[,] real;\index{{\tt \bfseries integrate\_ode }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, array[] real x\_r, array[] int x\_i): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the Dormand-Prince\nalgorithm, a 4th/5th order Runge-Kutta method.\n;
integrate_ode_adams;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i);array[,] real;\index{{\tt \bfseries integrate\_ode\_adams }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, data array[] real x\_r, data array[] int x\_i): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the Adams-Moulton method.\n;
integrate_ode_adams;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i, real rel_tol, real abs_tol, int max_num_steps);array[,] real;\index{{\tt \bfseries integrate\_ode\_adams }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, data array[] real x\_r, data array[] int x\_i, data real rel\_tol, data real abs\_tol, data int max\_num\_steps): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the Adams-Moulton\nmethod with additional control parameters for the solver.\n;
integrate_ode_bdf;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i);array[,] real;\index{{\tt \bfseries integrate\_ode\_bdf }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, data array[] real x\_r, data array[] int x\_i): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the backward differentiation\nformula (BDF) method.\n;
integrate_ode_bdf;(function ode, array[] real initial_state, real initial_time, array[] real times, array[] real theta, array[] real x_r, array[] int x_i, real rel_tol, real abs_tol, int max_num_steps);array[,] real;\index{{\tt \bfseries integrate\_ode\_bdf }!{\tt (function ode, array[] real initial\_state, real initial\_time, array[] real times, array[] real theta, data array[] real x\_r, data array[] int x\_i, data real rel\_tol, data real abs\_tol, data int max\_num\_steps): array[,] real}|hyperpage}\nSolves the ODE system for the times provided using the backward differentiation\nformula (BDF) method with additional control parameters for the solver.\n;
algebra_solver;(function algebra_system, vector y_guess, vector theta, data array[] real x_r, array[] int x_i, data real rel_tol, data real f_tol, int max_steps);vector;Solves the algebraic system, given an initial guess, using the Powell\nhybrid algorithm with additional control parameters for the solver.\n*Note:* In future releases, the function `algebra_solver` will be deprecated\nand replaced with `algebra_solver_powell`.\n;
algebra_solver_newton;(function algebra_system, vector y_guess, vector theta, data array[] real x_r, array[] int x_i);vector;Solves the algebraic system, given an initial guess, using Newton's method.\n;
algebra_solver_newton;(function algebra_system, vector y_guess, vector theta, data array[] real x_r, array[] int x_i, data real rel_tol, data real f_tol, int max_steps);vector;Solves the algebraic system, given an initial guess, using Newton's method\nwith additional control parameters for the solver.\n;
hmm_marginal;(matrix log_omega, matrix Gamma, vector rho);real;Returns the log probability density of $y$, with $x_n$ integrated out at each iteration.\nThe arguments represent (1) the log density of each output, (2) the transition matrix, and (3) the initial state vector.\n*   *`log_omega`*: $\log \omega_{kn} = \log p(y_n \mid x_n = k, \phi)$, log density of each output,\n*   *`Gamma`*: $\Gamma_{ij} = p(x_n = j | x_{n - 1} = i, \phi)$, the transition matrix,\n*   *`rho`*: $\rho_k = p(x_0 = k \mid \phi)$, the initial state probability.\n;
hmm_latent_rng;(matrix log_omega, matrix Gamma, vector rho);array[] int;Returns a length $N$ array of integers over $\{1, ..., K\}$,\nsampled from the joint posterior distribution of the hidden states,\n$p(x \mid \phi, y)$.\nMay be only used in transformed data and generated quantities.\n;
hmm_hidden_state_prob;(matrix log_omega, matrix Gamma, vector rho);matrix;Returns the matrix of marginal posterior probabilities of each hidden state value. This will be a $K \times N$ matrix.\nThe $n^\mathrm{th}$ column is a simplex of probabilities for the $n^\mathrm{th}$ variable.\nMoreover, let $A$ be the output. Then\n$A_{ij} = p(x_j = i \mid \phi, y)$.\nThis function may only be used in transformed data and generated quantities.\n;
pi;();real;$\pi$, the ratio of a circle's circumference to its diameter\n;
e;();real;$e$, the base of the natural logarithm\n;
sqrt2;();real;The square root of 2\n;
log2;();real;The natural logarithm of 2\n;
log10;();real;The natural logarithm of 10\n;
not_a_number;();real;Not-a-number, a special non-finite real value returned to signal an\nerror\n;
positive_infinity;();real;Positive infinity, a special non-finite real value larger than all\nfinite numbers\n;
negative_infinity;();real;Negative infinity, a special non-finite real value smaller than all\nfinite numbers\n;
machine_precision;();real;The smallest number $x$ such that $(x + 1) \neq 1$ in floating-point\narithmetic on the current hardware platform\n;
target;();real;Return the current value of the log probability accumulator.\n`target` acts like a function ending in `_lp`, meaning that it may only may only\nbe used in the model block.\n;
operator<;(int x, int y);int;;
operator<;(real x, real y);int;Return 1 if x is less than y and 0 otherwise. \begin{equation*} \text{operator<}(x,y)\n= \begin{cases} 1 & \text{if $x < y$} \\ 0 & \text{otherwise}\n\end{cases} \end{equation*}\n;
operator<=;(int x, int y);int;;
operator<=;(real x, real y);int;Return 1 if x is less than or equal y and 0 otherwise.\n\begin{equation*}\n\text{operator<=}(x,y) = \begin{cases} 1 & \text{if $x \leq y$} \\ 0 & \text{otherwise} \end{cases}\n\end{equation*}\n;
operator>;(int x, int y);int;;
operator>;(real x, real y);int;Return 1 if x is greater than y and 0 otherwise.\n\begin{equation*}\n\text{operator>}(x,y) = \begin{cases} 1 & \text{if $x > y$} \\ 0 & \text{otherwise} \end{cases}\n\end{equation*}\n;
operator>=;(int x, int y);int;;
operator>=;(real x, real y);int;Return 1 if x is greater than or equal to y and 0 otherwise.\n\begin{equation*}\n\text{operator>=}(x,y) = \begin{cases} 1 & \text{if $x \geq y$} \\ 0 & \text{otherwise} \end{cases}\n\end{equation*}\n;
operator==;(int x, int y);int;;
operator==;(real x, real y);int;Return 1 if x is equal to y and 0 otherwise.\n\begin{equation*}\n\text{operator==}(x,y) = \begin{cases} 1 & \text{if $x = y$} \\ 0 & \text{otherwise} \end{cases}\n\end{equation*}\n;
operator!=;(int x, int y);int;;
operator!=;(real x, real y);int;Return 1 if x is not equal to y and 0 otherwise. \begin{equation*}\n\text{operator!=}(x,y) = \begin{cases} 1 & \text{if $x \neq y$} \\ 0 &\n\text{otherwise} \end{cases} \end{equation*}\n;
operator!;(int x);int;Return 1 if x is zero and 0 otherwise. \begin{equation*} \text{operator!}(x) =\n\begin{cases} 0 & \text{if $x \neq 0$} \\ 1 & \text{if $x = 0$}\n\end{cases} \end{equation*}\n;
operator!;(real x);int;Return 1 if x is zero and 0 otherwise. \begin{equation*} \text{operator!}(x) =\n\begin{cases} 0 & \text{if $x \neq 0.0$} \\ 1 & \text{if $x = 0.0$}\n\end{cases} \end{equation*}\n**deprecated** - use `operator==` instead.\n;
operator&&;(int x, int y);int;Return 1 if x is unequal to 0 and y is unequal to 0. \begin{equation*}\n\mathrm{operator\&\&}(x,y) = \begin{cases} 1 & \text{if $x \neq 0$}\n\text{ and } y \neq 0\\ 0 & \text{otherwise} \end{cases} \end{equation*}\n;
operator&&;(real x, real y);int;Return 1 if x is unequal to 0.0 and y is unequal to 0.0. \begin{equation*}\n\mathrm{operator\&\&}(x,y) = \begin{cases} 1 & \text{if $x \neq 0.0$}\n\text{ and } y \neq 0.0\\ 0 & \text{otherwise} \end{cases} \end{equation*}\n**deprecated**\n;
operator||;(int x, int y);int;Return 1 if x is unequal to 0 or y is unequal to 0. \begin{equation*}\n\text{operator||}(x,y) = \begin{cases} 1 & \text{if $x \neq 0$}\n\textrm{ or } y \neq 0\\ 0 & \text{otherwise} \end{cases} \end{equation*}\n;
operator||;(real x, real y);int;Return 1 if x is unequal to 0.0 or y is unequal to 0.0. \begin{equation*}\n\text{operator||}(x,y) = \begin{cases} 1 & \text{if $x \neq 0.0$}\n\textrm{ or } y \neq 0.0\\ 0 & \text{otherwise} \end{cases} \end{equation*}\n**deprecated**\n;
step;(real x);real;Return 1 if x is positive and 0 otherwise. \begin{equation*} \text{step}(x) =\n\begin{cases} 0 & \text{if } x < 0 \\ 1 & \text{otherwise} \end{cases}\n\end{equation*} _**Warning:**_ `int_step(0)` and `int_step(NaN)` return 0 whereas\n`step(0)` and `step(NaN)` return 1.\nThe step function is often used in BUGS to perform conditional\noperations.  For instance, `step(a-b)` evaluates to 1 if `a` is\ngreater than `b` and evaluates to 0 otherwise. `step` is a step-like\nfunctions see the warning in section [step functions](#step-functions) applied to\nexpressions dependent on parameters.\n;
is_inf;(real x);int;Return 1 if x is infinite (positive or negative) and 0 otherwise.\n;
is_nan;(real x);int;Return 1 if x is NaN and 0 otherwise.\nCare must be taken because both of these indicator functions are\nstep-like and thus can cause discontinuities in gradients when applied\nto parameters see section [step-like functions](#step-functions) for details.\n;
operator+;(real x, real y);real;Return the sum of x and y. \begin{equation*} (x + y) = \text{operator+}(x,y) = x+y \end{equation*}\n;
operator-;(real x, real y);real;Return the difference between x and y. \begin{equation*} (x - y) =\n\text{operator-}(x,y) = x - y \end{equation*}\n;
operator*;(real x, real y);real;Return the product of x and y. \begin{equation*} (x * y) = \text{operator*}(x,y) = xy\n\end{equation*}\n;
operator/;(real x, real y);real;Return the quotient of x and y. \begin{equation*} (x / y) = \text{operator/}(x,y) =\n\frac{x}{y} \end{equation*}\n;
operator^;(real x, real y);real;Return x raised to the power of y. \begin{equation*} (x^\mathrm{\wedge}y) =\n\text{operator}^\mathrm{\wedge}(x,y) = x^y \end{equation*}\n;
operator-;(real x);real;Return the negation of the subtrahend x. \begin{equation*} \text{operator-}(x) = (-x)\n\end{equation*}\n;
operator-;(T x);T;Vectorized version of `operator-`. If `T x` is a (possibly nested) array of\nreals, `-x` is the same shape array where each individual number is negated.\n;
operator+;(real x);real;Return the value of x. \begin{equation*} \text{operator+}(x) = x \end{equation*}\n;
abs;(T x);T;The absolute value of x.\nThis function works elementwise over containers such as vectors.\nGiven a type `T` which is `real` `vector`, `row_vector`, `matrix`, or an array\nof those types, `abs` returns the same type where each element has had its\nabsolute value taken.\n;
fdim;(real x, real y);real;Return the positive difference between x and y, which is x - y if x is\ngreater than y and 0 otherwise see warning above.\n\begin{equation*} \text{fdim}(x,y) = \begin{cases} x-y &\n\text{if } x \geq y \\ 0 & \text{otherwise} \end{cases} \end{equation*}\n;
fdim;(T1 x, T2 y);R;Vectorized implementation of the `fdim` function\n;
fmin;(real x, real y);real;Return the minimum of x and y see warning above.\n\begin{equation*} \text{fmin}(x,y) = \begin{cases} x &\n\text{if } x \leq y \\ y & \text{otherwise} \end{cases} \end{equation*}\n;
fmin;(T1 x, T2 y);R;Vectorized implementation of the `fmin` function\n;
fmax;(real x, real y);real;Return the maximum of x and y see warning above.\n\begin{equation*} \text{fmax}(x,y) = \begin{cases} x &\n\text{if } x \geq y \\ y & \text{otherwise} \end{cases} \end{equation*}\n;
fmax;(T1 x, T2 y);R;Vectorized implementation of the `fmax` function\n;
fmod;(real x, real y);real;Return the real value remainder after dividing x by y see warning above.\n\begin{equation*} \text{fmod}(x,y) = x - \left\lfloor \frac{x}{y} \right\rfloor \, y \end{equation*}\nThe operator $\lfloor u \rfloor$ is the floor operation see below.\n;
fmod;(T1 x, T2 y);R;Vectorized implementation of the `fmod` function\n;
floor;(T x);R;The floor of x, which is the largest integer less than or equal to x,\nconverted to a real value see warning at start of section\n[step-like functions](#step-functions)\n;
ceil;(T x);R;The ceiling of x, which is the smallest integer greater than or equal to\nx, converted to a real value see warning at start of section\n[step-like functions](#step-functions)\n;
round;(T x);R;The nearest integer to x, converted to a real value see warning at start\nof section [step-like functions](#step-functions)\n;
trunc;(T x);R;The integer nearest to but no larger in magnitude than x, converted to a\ndouble value see warning at start of section [step-like functions](#step-functions)\n;
sqrt;(T x);R;The square root of x\n;
cbrt;(T x);R;The cube root of x\n;
square;(T x);R;The square of x\n;
exp;(T x);R;The natural exponential of x\n;
exp2;(T x);R;The base-2 exponential of x\n;
log;(T x);R;The natural logarithm of x\n;
log2;(T x);R;The base-2 logarithm of x\n;
log10;(T x);R;The base-10 logarithm of x\n;
pow;(real x, real y);real;Return x raised to the power of y. \begin{equation*} \text{pow}(x,y) = x^y \end{equation*}\n;
pow;(T1 x, T2 y);R;Vectorized implementation of the `pow` function\n;
inv;(T x);R;The inverse of x\n;
inv_sqrt;(T x);R;The inverse of the square root of x\n;
inv_square;(T x);R;The inverse of the square of x\n;
hypot;(real x, real y);real;Return the length of the hypotenuse of a right triangle with sides of\nlength x and y. \begin{equation*} \text{hypot}(x,y) = \begin{cases} \sqrt{x^2+y^2} &\n\text{if } x,y\geq 0 \\ \textrm{NaN} & \text{otherwise} \end{cases} \end{equation*}\n;
hypot;(T1 x, T2 y);R;Vectorized implementation of the `hypot` function\n;
cos;(T x);R;The cosine of the angle x (in radians)\n;
sin;(T x);R;The sine of the angle x (in radians)\n;
tan;(T x);R;The tangent of the angle x (in radians)\n;
acos;(T x);R;The principal arc (inverse) cosine (in radians) of x\n;
asin;(T x);R;The principal arc (inverse) sine (in radians) of x\n;
atan;(T x);R;The principal arc (inverse) tangent (in radians) of x, with values from\n$-\pi/2$ to $\pi/2$\n;
atan2;(T y, T x);R;Return the principal arc (inverse) tangent (in radians) of y divided\nby x, \begin{equation*} \text{atan2}(y, x) = \arctan\left(\frac{y}{x}\right) \end{equation*}\n;
cosh;(T x);R;The hyperbolic cosine of x (in radians)\n;
sinh;(T x);R;The hyperbolic sine of x (in radians)\n;
tanh;(T x);R;The hyperbolic tangent of x (in radians)\n;
acosh;(T x);R;The inverse hyperbolic cosine (in radians)\n;
asinh;(T x);R;The inverse hyperbolic cosine (in radians)\n;
atanh;(T x);R;The inverse hyperbolic tangent (in radians) of x\n;
logit;(T x);R;The log odds, or logit, function applied to x\n;
inv_logit;(T x);R;The logistic sigmoid function applied to x\n;
inv_cloglog;(T x);R;The inverse of the complementary log-log function applied to x\n;
erf;(T x);R;The error function, also known as the Gauss error function, of x\n;
erfc;(T x);R;The complementary error function of x\n;
inv_erfc;(T x);R;The inverse of the complementary error function of x\n;
Phi;(T x);R;The standard normal cumulative distribution function of x\n;
inv_Phi;(T x);R;Return the value of the inverse standard normal cdf $\Phi^{-1}$ at the\nspecified quantile `x`. The details of the algorithm can be found in [@Wichura:1988].\nQuantile arguments below 1e-16 are untested quantiles above 0.999999999 result in increasingly large errors.\n;
Phi_approx;(T x);R;The fast approximation of the unit (may replace `Phi` for probit\nregression with maximum absolute error of 0.00014, see\n[@BowlingEtAl:2009] for details)\n;
binary_log_loss;(int y, real y_hat);real;Return the log loss function for for predicting $\hat{y} \in [0,1]$\nfor boolean outcome $y \in \{0,1\}$.\n\begin{equation*}\n\mathrm{binary\_log\_loss}(y,\hat{y}) = \begin{cases} -\log \hat{y} &\n \text{if } y = 1\\ -\log (1 - \hat{y}) & \text{otherwise} \end{cases}\n\end{equation*}\n;
binary_log_loss;(T1 x, T2 y);R;Vectorized implementation of the `binary_log_loss` function\n;
owens_t;(real h, real a);real;Return the Owen's T function for the probability of the event $X > h$\nand $0<Y<aX$ where X and Y are independent standard normal random\nvariables. \begin{equation*} \mathrm{owens\_t}(h,a) = \frac{1}{2\pi} \int_0^a\n\frac{\exp(-\frac{1}{2}h^2(1+x^2))}{1+x^2}dx \end{equation*}\n;
owens_t;(T1 x, T2 y);R;Vectorized implementation of the `owens_t` function\n;
beta;(real alpha, real beta);real;Return the beta function applied to alpha and beta. The beta function,\n$\text{B}(\alpha,\beta)$, computes the normalizing constant for the beta\ndistribution, and is defined for $\alpha > 0$ and $\beta > 0$. See section\n[appendix](mathematical_functions.qmd#beta-appendix) for definition of $\text{B}(\alpha, \beta)$.\n;
beta;(T1 x, T2 y);R;Vectorized implementation of the `beta` function\n;
inc_beta;(real alpha, real beta, real x);real;Return the regularized incomplete beta function up to x applied to alpha and beta.\nSee section [appendix](mathematical_functions.qmd#inc-beta-appendix) for a definition.\n;
inv_inc_beta;(real alpha, real beta, real p);real;Return the inverse of the regularized incomplete beta function. The return value\n`x` is the value that solves `p = inc_beta(alpha, beta, x)`.\nSee section [appendix](mathematical_functions.qmd#inc-beta-appendix) for a definition of the `inc_beta`.\n;
lbeta;(real alpha, real beta);real;Return the natural logarithm of the beta function applied to alpha and\nbeta. The beta function, $\text{B}(\alpha,\beta)$, computes the\nnormalizing constant for the beta distribution, and is defined for\n$\alpha > 0$ and $\beta > 0$.\n\begin{equation*}\n\text{lbeta}(\alpha,\beta) = \log \Gamma(a) + \log \Gamma(b) - \log \Gamma(a+b)\n\end{equation*}\nSee section [appendix](mathematical_functions.qmd#beta-appendix) for definition of $\text{B}(\alpha, \beta)$.\n;
lbeta;(T1 x, T2 y);R;Vectorized implementation of the `lbeta` function\n;
tgamma;(T x);R;The gamma function applied to x. The gamma function is the generalization\nof the factorial function to continuous variables, defined so that\n$\Gamma(n+1) = n!$. See for a full definition of $\Gamma(x)$. The\nfunction is defined for positive numbers and non-integral negative\nnumbers,\n;
lgamma;(T x);R;The natural logarithm of the gamma function applied to x,\n;
digamma;(T x);R;The digamma function applied to x. The digamma function is the derivative\nof the natural logarithm of the Gamma function. The function is\ndefined for positive numbers and non-integral negative numbers\n;
trigamma;(T x);R;The trigamma function applied to x. The trigamma function is the second\nderivative of the natural logarithm of the Gamma function\n;
lmgamma;(int n, real x);real;Return the natural logarithm of the multivariate gamma function\n$\Gamma_n$ with n dimensions applied to x.\n\begin{equation*}\n\text{lmgamma}(n,x) =\n \begin{cases} \frac{n(n-1)}{4} \log \pi + \sum_{j=1}^n \log \Gamma\left(x + \frac{1 - j}{2}\right)\n & \text{if } x\not\in \{\dots,-3,-2,-1,0\}\\ \textrm{error} & \text{otherwise} \end{cases}\n\end{equation*}\n;
lmgamma;(T1 x, T2 y);R;Vectorized implementation of the `lmgamma` function\n;
gamma_p;(real a, real z);real;Return the normalized lower incomplete gamma function of a and z\ndefined for positive a and nonnegative z.\n\begin{equation*}\n\mathrm{gamma\_p}(a,z) =\n\begin{cases} \frac{1}{\Gamma(a)}\int_0^zt^{a-1}e^{-t}dt &\n\text{if } a > 0, z \geq 0 \\ \textrm{error} & \text{otherwise} \end{cases}\n\end{equation*}\n;
gamma_p;(T1 x, T2 y);R;Vectorized implementation of the `gamma_p` function\n;
gamma_q;(real a, real z);real;Return the normalized upper incomplete gamma function of a and z\ndefined for positive a and nonnegative z.\n\begin{equation*}\n\mathrm{gamma\_q}(a,z) =\n \begin{cases} \frac{1}{\Gamma(a)}\int_z^\infty t^{a-1}e^{-t}dt &\n \text{if } a > 0, z \geq 0 \\[6pt] \textrm{error} & \text{otherwise}\n\end{cases}\n\end{equation*}\n;
gamma_q;(T1 x, T2 y);R;Vectorized implementation of the `gamma_q` function\n;
choose;(int x, int y);int;Return the binomial coefficient of x and y. For non-negative integer\ninputs, the binomial coefficient function is written as $\binom{x}{y}$\nand pronounced "x choose y." In its the antilog of the `lchoose`\nfunction but returns an integer rather than a real number with no\nnon-zero decimal places. For $0 \leq y \leq x$, the binomial\ncoefficient function can be defined via the factorial function\n\begin{equation*}\n\text{choose}(x,y) = \frac{x!}{\left(y!\right)\left(x - y\right)!}.\n\end{equation*}\n;
choose;(T1 x, T2 y);R;Vectorized implementation of the `choose` function\n;
bessel_first_kind;(int v, real x);real;Return the Bessel function of the first kind with order v applied to x.\n\begin{equation*}\n\mathrm{bessel\_first\_kind}(v,x) = J_v(x),\n\end{equation*}\nwhere\n\begin{equation*}\nJ_v(x)=\left(\frac{1}{2}x\right)^v \sum_{k=0}^\infty\n\frac{\left(-\frac{1}{4}x^2\right)^k}{k!\, \Gamma(v+k+1)}\n\end{equation*}\n;
bessel_first_kind;(T1 x, T2 y);R;Vectorized implementation of the `bessel_first_kind` function\n;
bessel_second_kind;(int v, real x);real;Return the Bessel function of the second kind with order v applied to\nx defined for positive x and v. For $x,v > 0$,\n\begin{equation*}\n\mathrm{bessel\_second\_kind}(v,x) =\n \begin{cases} Y_v(x) & \text{if } x > 0 \\ \textrm{error} & \text{otherwise} \end{cases}\n\end{equation*}\nwhere\n\begin{equation*}\nY_v(x)=\frac{J_v(x)\cos(v\pi)-J_{-v}(x)}{\sin(v\pi)}\n\end{equation*}\n;
bessel_second_kind;(T1 x, T2 y);R;Vectorized implementation of the `bessel_second_kind` function\n;
modified_bessel_first_kind;(int v, real z);real;Return the modified Bessel function of the first kind with order v\napplied to z defined for all z and integer v.\n\begin{equation*}\n\mathrm{modified\_bessel\_first\_kind}(v,z) = I_v(z)\n\end{equation*}\nwhere\n\begin{equation*}\n{I_v}(z) = \left(\frac{1}{2}z\right)^v\sum_{k=0}^\infty \frac{\left(\frac{1}{4}z^2\right)^k}{k!\Gamma(v+k+1)}\n\end{equation*}\n;
modified_bessel_first_kind;(T1 x, T2 y);R;Vectorized implementation of the `modified_bessel_first_kind` function\n;
log_modified_bessel_first_kind;(real v, real z);real;Return the log of the modified Bessel function of the first kind. v does\nnot have to be an integer.\n;
log_modified_bessel_first_kind;(T1 x, T2 y);R;Vectorized implementation of the `log_modified_bessel_first_kind` function\n;
modified_bessel_second_kind;(int v, real z);real;Return the modified Bessel function of the second kind with order v\napplied to z defined for positive z and integer v.\n\begin{equation*}\n\mathrm{modified\_bessel\_second\_kind}(v,z) =\n \begin{cases} K_v(z) &  \text{if } z > 0 \\ \textrm{error} & \text{if } z \leq 0 \end{cases}\n\end{equation*}\nwhere\n\begin{equation*} {K_v}(z) = \frac{\pi}{2}\cdot\frac{I_{-v}(z) - I_{v}(z)}{\sin(v\pi)}\n\end{equation*}\n;
modified_bessel_second_kind;(T1 x, T2 y);R;Vectorized implementation of the `modified_bessel_second_kind` function\n;
falling_factorial;(real x, real n);real;Return the falling factorial of x with power n defined for positive x and real n.\n\begin{equation*}\n\mathrm{falling\_factorial}(x,n) =\n\begin{cases} (x)_n & \text{if } x > 0 \\ \textrm{error} & \text{if } x \leq 0 \end{cases}\n\end{equation*}\nwhere\n\begin{equation*}\n(x)_n=\frac{\Gamma(x+1)}{\Gamma(x-n+1)}\n\end{equation*}\n;
falling_factorial;(T1 x, T2 y);R;Vectorized implementation of the `falling_factorial` function\n;
lchoose;(real x, real y);real;Return the natural logarithm of the generalized binomial coefficient\nof x and y. For non-negative integer inputs, the binomial coefficient\nfunction is written as $\binom{x}{y}$ and pronounced "x choose y."\nThis function generalizes to real numbers using the gamma function.\nFor $0 \leq y \leq x$, \begin{equation*} \mathrm{binomial\_coefficient\_log}(x,y) =\n\log\Gamma(x+1) - \log\Gamma(y+1) - \log\Gamma(x-y+1). \end{equation*}\n;
lchoose;(T1 x, T2 y);R;Vectorized implementation of the `lchoose` function\n;
log_falling_factorial;(real x, real n);real;Return the log of the falling factorial of x with power n defined for\npositive x and real n. \begin{equation*} \mathrm{log\_falling\_factorial}(x,n) =\n\begin{cases} \log (x)_n & \text{if } x > 0 \\ \textrm{error} &\n\text{if } x \leq 0 \end{cases} \end{equation*}\n;
rising_factorial;(real x, int n);real;Return the rising factorial of x with power n defined for positive x and integer n.\n\begin{equation*}\n\mathrm{rising\_factorial}(x,n) = \begin{cases} x^{(n)} & \text{if } x > 0 \\ \textrm{error} & \text{if } x \leq 0 \end{cases}\n\end{equation*}\nwhere\n\begin{equation*} x^{(n)}=\frac{\Gamma(x+n)}{\Gamma(x)} \end{equation*}\n;
rising_factorial;(T1 x, T2 y);R;Vectorized implementation of the `rising_factorial` function\n;
log_rising_factorial;(real x, real n);real;Return the log of the rising factorial of x with power n defined for\npositive x and real n. \begin{equation*} \mathrm{log\_rising\_factorial}(x,n) =\n\begin{cases} \log x^{(n)} & \text{if } x > 0 \\ \textrm{error} &\n\text{if } x \leq 0 \end{cases} \end{equation*}\n;
log_rising_factorial;(T1 x, T2 y);R;Vectorized implementation of the `log_rising_factorial` function\n;
expm1;(T x);R;The natural exponential of x minus 1\n;
fma;(real x, real y, real z);real;Return z plus the result of x multiplied by y. \begin{equation*} \text{fma}(x,y,z) =\n(x \times y) + z \end{equation*}\n;
ldexp;(real x, int y);real;Return the product of x and two raised to the y power. \begin{equation*}\n\text{ldexp}(x,y) = x 2^y  \end{equation*}\n;
ldexp;(T1 x, T2 y);R;Vectorized implementation of the `ldexp` function\n;
lmultiply;(real x, real y);real;Return the product of x and the natural logarithm of y. \begin{equation*}\n\text{lmultiply}(x,y) = \begin{cases} 0 & \text{if } x = y = 0 \\ x\n\log y & \text{if } x, y \neq 0 \\ \text{NaN} & \text{otherwise}\n\end{cases} \end{equation*}\n;
lmultiply;(T1 x, T2 y);R;Vectorized implementation of the `lmultiply` function\n;
log1p;(T x);R;The natural logarithm of 1 plus x\n;
log1m;(T x);R;The natural logarithm of 1 minus x\n;
log1p_exp;(T x);R;The natural logarithm of one plus the natural exponentiation of x\n;
log1m_exp;(T x);R;The logarithm of one minus the natural exponentiation of x\n;
log_diff_exp;(real x, real y);real;Return the natural logarithm of the difference of the natural\nexponentiation of x and the natural exponentiation of y. \begin{equation*}\n\mathrm{log\_diff\_exp}(x,y) = \begin{cases} \log(\exp(x)-\exp(y)) &\n\text{if } x > y \\[6pt] \textrm{NaN} & \text{otherwise} \end{cases}\n\end{equation*}\n;
log_diff_exp;(T1 x, T2 y);R;Vectorized implementation of the `log_diff_exp` function\n;
log_mix;(real theta, real lp1, real lp2);real;Return the log mixture of the log densities lp1 and lp2 with mixing\nproportion theta, defined by \begin{eqnarray*}\n\mathrm{log\_mix}(\theta, \lambda_1, \lambda_2) & = & \log \!\left(\n\theta \exp(\lambda_1) + \left( 1 - \theta \right) \exp(\lambda_2)\n\right) \\[3pt] & = & \mathrm{log\_sum\_exp}\!\left(\log(\theta) +\n\lambda_1, \ \log(1 - \theta) + \lambda_2\right). \end{eqnarray*}\n;
log_mix;(T1 theta, T2 lp1, T3 lp2);R;Vectorized implementation of the `log_mix` function\n;
log_sum_exp;(T1 x, T2 y);R;Return the natural logarithm of the sum of the natural exponentiation\nof x and the natural exponentiation of y. \begin{equation*}\n\mathrm{log\_sum\_exp}(x,y) = \log(\exp(x)+\exp(y)) \end{equation*}\n;
log_inv_logit;(T x);R;The natural logarithm of the inverse logit function of x\n;
log_inv_logit_diff;(T1 x, T2 y);R;The natural logarithm of the difference of the inverse logit function of x and the inverse logit function of y\n;
log1m_inv_logit;(T x);R;The natural logarithm of 1 minus the inverse logit function of x\n;
lambert_w0;(reals x);R;Implementation of the $W_0$ branch of the Lambert W function, i.e., solution to the function $W_0(x) \exp^{ W_0(x)} = x$\n;
lambert_wm1;(T x);R;Implementation of the $W_{-1}$ branch of the Lambert W function, i.e., solution to the function $W_{-1}(x) \exp^{W_{-1}(x)} = x$\n;
multinomial;~;real;Increment target log probability density with `multinomial_lupmf(y | theta)`.;
multinomial_lpmf;(array[] int y | vector theta);real;The log multinomial probability mass function with outcome array `y`\nof size $K$ given the $K$-simplex distribution parameter theta and\n(implicit) total count `N = sum(y)`\n;
multinomial_lupmf;(array[] int y | vector theta);real;The log multinomial probability mass function with outcome array `y`\nof size $K$ given the $K$-simplex distribution parameter theta and\n(implicit) total count `N = sum(y)` dropping constant additive terms\n;
multinomial_rng;(vector theta, int N);array[] int;Generate a multinomial variate with simplex distribution parameter\ntheta and total count $N$ may only be used in transformed data and\ngenerated quantities blocks\n;
multinomial_logit;~;real;Increment target log probability density with `multinomial_logit_lupmf(y | gamma)`.;
multinomial_logit_lpmf;(array[] int y | vector gamma);real;The log multinomial probability mass function with outcome array `y`\nof size $K$ given the log $K$-simplex distribution parameter $\gamma$ and\n(implicit) total count `N = sum(y)`\n;
multinomial_logit_lupmf;(array[] int y | vector gamma);real;The log multinomial probability mass function with outcome array `y`\nof size $K$ given the log $K$-simplex distribution parameter $\gamma$ and (implicit) total count `N = sum(y)` dropping constant additive\nterms\n;
multinomial_logit_rng;(vector gamma, int N);array[] int;Generate a variate from a multinomial distribution with probabilities\n`softmax(gamma)` and total count `N` may only be used in transformed data and\ngenerated quantities blocks.\n;
dirichlet_multinomial;~;real;Increment target log probability density with `dirichlet_multinomial_lupmf(y | alpha)`.;
dirichlet_multinomial_lpmf;(array[] int y | vector alpha);real;The log multinomial probability mass function with outcome array `y`\nwith $K$ elements given the positive $K$-vector distribution parameter `alpha` and\n(implicit) total count `N = sum(y)`.\n;
dirichlet_multinomial_lupmf;(array[] int y | vector alpha);real;The log multinomial probability mass function with outcome array `y`\nwith $K$ elements, given the positive $K$-vector distribution parameter `alpha` and\n(implicit) total count `N = sum(y)` dropping constant additive terms.\n;
dirichlet_multinomial_rng;(vector alpha, int N);array[] int;Generate a multinomial variate with positive vector distribution parameter\n`alpha` and total count `N` may only be used in transformed data and\ngenerated quantities blocks. This is equivalent to `multinomial_rng(dirichlet_rng(alpha), N)`.\n;
normal;~;real;Increment target log probability density with `normal_lupdf(y | mu, sigma)`.;
normal_lpdf;(reals y | reals mu, reals sigma);real;The log of the normal density of y given location mu and scale sigma\n;
normal_lupdf;(reals y | reals mu, reals sigma);real;The log of the normal density of y given location mu and scale sigma dropping\nconstant additive terms.\n;
normal_cdf;(reals y | reals mu, reals sigma);real;The cumulative normal distribution of y given location mu and scale\nsigma normal_cdf will underflow to 0 for $\frac{{y}-{\mu}}{{\sigma}}$\nbelow -37.5 and overflow to 1 for $\frac{{y}-{\mu}}{{\sigma}}$ above\n8.25 the function `Phi_approx` is more robust in the tails, but must\nbe scaled and translated for anything other than a standard normal.\n;
normal_lcdf;(reals y | reals mu, reals sigma);real;The log of the cumulative normal distribution of y given location mu\nand scale sigma normal_lcdf will underflow to $-\infty$ for\n$\frac{{y}-{\mu}}{{\sigma}}$ below -37.5 and overflow to 0 for\n$\frac{{y}-{\mu}}{{\sigma}}$ above 8.25 `log(Phi_approx(...))` is more\nrobust in the tails, but must be scaled and translated for anything other\nthan a standard normal.\n;
normal_lccdf;(reals y | reals mu, reals sigma);real;The log of the complementary cumulative normal distribution of y given\nlocation mu and scale sigma normal_lccdf will overflow to 0 for\n$\frac{{y}-{\mu}}{{\sigma}}$ below -37.5 and underflow to $-\infty$\nfor $\frac{{y}-{\mu}}{{\sigma}}$ above 8.25 `log1m(Phi_approx(...))` is\nmore robust in the tails, but must be scaled and translated for anything\nother than a standard normal.\n;
normal_rng;(reals mu, reals sigma);R;Generate a normal variate with location mu and scale sigma may only\nbe used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
std_normal;~;real;Increment target log probability density with `std_normal_lupdf(y)`.;
std_normal_lpdf;(reals y);real;The standard normal (location zero, scale one) log probability density\nof y.\n;
std_normal_lupdf;(reals y);real;The standard normal (location zero, scale one) log probability density\nof y dropping constant additive terms.\n;
std_normal_cdf;(reals y);real;The cumulative standard normal distribution of y std_normal_cdf will\nunderflow to 0 for $y$ below -37.5 and overflow to 1 for $y$ above 8.25\nthe function `Phi_approx` is more robust in the tails.\n;
std_normal_lcdf;(reals y);real;The log of the cumulative standard normal distribution of y std_normal_lcdf\nwill underflow to $-\infty$ for $y$ below -37.5 and overflow to 0 for $y$\nabove 8.25 `log(Phi_approx(...))` is more robust in the tails.\n;
std_normal_lccdf;(reals y);real;The log of the complementary cumulative standard normal distribution of y\nstd_normal_lccdf will overflow to 0 for $y$ below -37.5 and underflow to\n$-\infty$ for $y$ above 8.25 `log1m(Phi_approx(...))` is more robust in the\ntails.\n;
std_normal_qf;(T x);R;Returns the value of the inverse standard normal cdf $\Phi^{-1}$ at the\nspecified quantile `x`. The `std_normal_qf` is equivalent to the\n`inv_Phi` function.\n;
std_normal_log_qf;(T x);R;Return the value of the inverse standard normal cdf $\Phi^{-1}$ evaluated\nat the log of the specified quantile `x`. This function is equivalent to\n`std_normal_qf(exp(x))` but is more numerically stable.\n;
std_normal_rng;();real;Generate a normal variate with location zero and scale one may only\nbe used in transformed data and generated quantities blocks.\n;
normal_id_glm;~;real;Increment target log probability density with `normal_id_glm_lupdf(y | x, alpha, beta, sigma)`.;
normal_id_glm_lpdf;(real y | matrix x, real alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(real y | matrix x, real alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(real y | matrix x, vector alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(real y | matrix x, vector alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(real y | matrix x, real alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(real y | matrix x, real alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(real y | matrix x, vector alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(real y | matrix x, vector alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(vector y | row_vector x, real alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(vector y | row_vector x, real alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(vector y | row_vector x, vector alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(vector y | row_vector x, vector alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(vector y | matrix x, real alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(vector y | matrix x, real alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(vector y | matrix x, vector alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(vector y | matrix x, vector alpha, vector beta, real sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(vector y | matrix x, real alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(vector y | matrix x, real alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
normal_id_glm_lpdf;(vector y | matrix x, vector alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma`.\n;
normal_id_glm_lupdf;(vector y | matrix x, vector alpha, vector beta, vector sigma);real;The log normal probability density of `y` given location `alpha + x * beta`\nand scale `sigma` dropping constant additive terms.\n;
exp_mod_normal;~;real;Increment target log probability density with `exp_mod_normal_lupdf(y | mu, sigma, lambda)`.;
exp_mod_normal_lpdf;(reals y | reals mu, reals sigma, reals lambda);real;The log of the exponentially modified normal density of y given\nlocation mu, scale sigma, and shape lambda\n;
exp_mod_normal_lupdf;(reals y | reals mu, reals sigma, reals lambda);real;The log of the exponentially modified normal density of y given\nlocation mu, scale sigma, and shape lambda dropping constant additive terms\n;
exp_mod_normal_cdf;(reals y | reals mu, reals sigma, reals lambda);real;The exponentially modified normal cumulative distribution function of\ny given location mu, scale sigma, and shape lambda\n;
exp_mod_normal_lcdf;(reals y | reals mu, reals sigma, reals lambda);real;The log of the exponentially modified normal cumulative distribution\nfunction of y given location mu, scale sigma, and shape lambda\n;
exp_mod_normal_lccdf;(reals y | reals mu, reals sigma, reals lambda);real;The log of the exponentially modified normal complementary cumulative\ndistribution function of y given location mu, scale sigma, and shape\nlambda\n;
exp_mod_normal_rng;(reals mu, reals sigma, reals lambda);R;Generate a exponentially modified normal variate with location mu,\nscale sigma, and shape lambda may only be used in transformed data and generated\nquantities blocks. For a description of argument and return types, see\nsection [vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
skew_normal;~;real;Increment target log probability density with `skew_normal_lupdf(y | xi, omega, alpha)`.;
skew_normal_lpdf;(reals y | reals xi, reals omega, reals alpha);real;The log of the skew normal density of y given location xi, scale\nomega, and shape alpha\n;
skew_normal_lupdf;(reals y | reals xi, reals omega, reals alpha);real;The log of the skew normal density of y given location xi, scale\nomega, and shape alpha dropping constant additive terms\n;
skew_normal_cdf;(reals y | reals xi, reals omega, reals alpha);real;The skew normal distribution function of y given location xi, scale\nomega, and shape alpha\n;
skew_normal_lcdf;(reals y | reals xi, reals omega, reals alpha);real;The log of the skew normal cumulative distribution function of y given\nlocation xi, scale omega, and shape alpha\n;
skew_normal_lccdf;(reals y | reals xi, reals omega, reals alpha);real;The log of the skew normal complementary cumulative distribution\nfunction of y given location xi, scale omega, and shape alpha\n;
skew_normal_rng;(reals xi, reals omega, real alpha);R;Generate a skew normal variate with location xi, scale omega, and\nshape alpha may only be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
student_t;~;real;Increment target log probability density with `student_t_lupdf(y | nu, mu, sigma)`.;
student_t_lpdf;(reals y | reals nu, reals mu, reals sigma);real;The log of the Student-$t$ density of y given degrees of freedom nu,\nlocation mu, and scale sigma\n;
student_t_lupdf;(reals y | reals nu, reals mu, reals sigma);real;The log of the Student-$t$ density of y given degrees of freedom nu,\nlocation mu, and scale sigma dropping constant additive terms\n;
student_t_cdf;(reals y | reals nu, reals mu, reals sigma);real;The Student-$t$ cumulative distribution function of y given degrees of\nfreedom nu, location mu, and scale sigma\n;
student_t_lcdf;(reals y | reals nu, reals mu, reals sigma);real;The log of the Student-$t$ cumulative distribution function of y given\ndegrees of freedom nu, location mu, and scale sigma\n;
student_t_lccdf;(reals y | reals nu, reals mu, reals sigma);real;The log of the Student-$t$ complementary cumulative distribution\nfunction of y given degrees of freedom nu, location mu, and scale\nsigma\n;
student_t_rng;(reals nu, reals mu, reals sigma);R;Generate a Student-$t$ variate with degrees of freedom nu, location\nmu, and scale sigma may only be used in transformed data and generated\nquantities blocks. For a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
cauchy;~;real;Increment target log probability density with `cauchy_lupdf(y | mu, sigma)`.;
cauchy_lpdf;(reals y | reals mu, reals sigma);real;The log of the Cauchy density of y given location mu and scale sigma\n;
cauchy_lupdf;(reals y | reals mu, reals sigma);real;The log of the Cauchy density of y given location mu and scale sigma\ndropping constant additive terms\n;
cauchy_cdf;(reals y | reals mu, reals sigma);real;The Cauchy cumulative distribution function of y given location mu and\nscale sigma\n;
cauchy_lcdf;(reals y | reals mu, reals sigma);real;The log of the Cauchy cumulative distribution function of y given\nlocation mu and scale sigma\n;
cauchy_lccdf;(reals y | reals mu, reals sigma);real;The log of the Cauchy complementary cumulative distribution function\nof y given location mu and scale sigma\n;
cauchy_rng;(reals mu, reals sigma);R;Generate a Cauchy variate with location mu and scale sigma may only\nbe used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
double_exponential;~;real;Increment target log probability density with `double_exponential_lupdf(y | mu, sigma)`.;
double_exponential_lpdf;(reals y | reals mu, reals sigma);real;The log of the double exponential density of y given location mu and\nscale sigma\n;
double_exponential_lupdf;(reals y | reals mu, reals sigma);real;The log of the double exponential density of y given location mu and\nscale sigma dropping constant additive terms\n;
double_exponential_cdf;(reals y | reals mu, reals sigma);real;The double exponential cumulative distribution function of y given\nlocation mu and scale sigma\n;
double_exponential_lcdf;(reals y | reals mu, reals sigma);real;The log of the double exponential cumulative distribution function of\ny given location mu and scale sigma\n;
double_exponential_lccdf;(reals y | reals mu, reals sigma);real;The log of the double exponential complementary cumulative\ndistribution function of y given location mu and scale sigma\n;
double_exponential_rng;(reals mu, reals sigma);R;Generate a double exponential variate with location mu and scale\nsigma may only be used in transformed data and generated quantities blocks. For a\ndescription of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
logistic;~;real;Increment target log probability density with `logistic_lupdf(y | mu, sigma)`.;
logistic_lpdf;(reals y | reals mu, reals sigma);real;The log of the logistic density of y given location mu and scale sigma\n;
logistic_lupdf;(reals y | reals mu, reals sigma);real;The log of the logistic density of y given location mu and scale sigma\ndropping constant additive terms\n;
logistic_cdf;(reals y | reals mu, reals sigma);real;The logistic cumulative distribution function of y given location mu\nand scale sigma\n;
logistic_lcdf;(reals y | reals mu, reals sigma);real;The log of the logistic cumulative distribution function of y given\nlocation mu and scale sigma\n;
logistic_lccdf;(reals y | reals mu, reals sigma);real;The log of the logistic complementary cumulative distribution function\nof y given location mu and scale sigma\n;
logistic_rng;(reals mu, reals sigma);R;Generate a logistic variate with location mu and scale sigma may only\nbe used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
gumbel;~;real;Increment target log probability density with `gumbel_lupdf(y | mu, beta)`.;
gumbel_lpdf;(reals y | reals mu, reals beta);real;The log of the gumbel density of y given location mu and scale beta\n;
gumbel_lupdf;(reals y | reals mu, reals beta);real;The log of the gumbel density of y given location mu and scale beta\ndropping constant additive terms\n;
gumbel_cdf;(reals y | reals mu, reals beta);real;The gumbel cumulative distribution function of y given location mu and\nscale beta\n;
gumbel_lcdf;(reals y | reals mu, reals beta);real;The log of the gumbel cumulative distribution function of y given\nlocation mu and scale beta\n;
gumbel_lccdf;(reals y | reals mu, reals beta);real;The log of the gumbel complementary cumulative distribution function\nof y given location mu and scale beta\n;
gumbel_rng;(reals mu, reals beta);R;Generate a gumbel variate with location mu and scale beta may only be\nused in transformed data and generated quantities blocks. For a description\nof argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
skew_double_exponential;~;real;Increment target log probability density with `skew_double_exponential(y | mu, sigma, tau)`;
skew_double_exponential_lpdf;(reals y | reals mu, reals sigma, reals tau);real;The log of the skew double exponential density of y given location mu, scale sigma and skewness tau\n;
skew_double_exponential_lupdf;(reals y | reals mu, reals sigma, reals tau);real;The log of the skew double exponential density of y given location mu, scale sigma and skewness tau dropping constant additive terms\n;
skew_double_exponential_cdf;(reals y | reals mu, reals sigma, reals tau);real;The skew double exponential cumulative distribution function of y given\nlocation mu, scale sigma and skewness tau\n;
skew_double_exponential_lcdf;(reals y | reals mu, reals sigma, reals tau);real;The log of the skew double exponential cumulative distribution function of\ny given location mu, scale sigma and skewness tau\n;
skew_double_exponential_lccdf;(reals y | reals mu, reals sigma, reals tau);real;The log of the skew double exponential complementary cumulative\ndistribution function of y given location mu, scale sigma and skewness tau\n;
skew_double_exponential_rng;(reals mu, reals sigma);R;Generate a skew double exponential variate with location mu, scale\nsigma and skewness tau may only be used in transformed data and generated quantities blocks. For a\ndescription of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
cov_exp_quad;(row_vectors x, real alpha, real rho);matrix;The covariance matrix with an exponentiated quadratic kernel of x.\n;
cov_exp_quad;(vectors x, real alpha, real rho);matrix;The covariance matrix with an exponentiated quadratic kernel of x.\n;
cov_exp_quad;(array[] real x, real alpha, real rho);matrix;The covariance matrix with an exponentiated quadratic kernel of x.\n;
cov_exp_quad;(row_vectors x1, row_vectors x2, real alpha, real rho);matrix;The covariance matrix with an exponentiated quadratic kernel of x1 and\nx2.\n;
cov_exp_quad;(vectors x1, vectors x2, real alpha, real rho);matrix;The covariance matrix with an exponentiated quadratic kernel of x1 and\nx2.\n;
cov_exp_quad;(array[] real x1, array[] real x2, real alpha, real rho);matrix;The covariance matrix with an exponentiated quadratic kernel of x1 and\nx2.\n;
binomial;~;real;{{< since 2.0 >}};
binomial_lpmf;(ints n | ints N, reals theta);real;The log binomial probability mass of n successes in N trials given\nchance of success theta\n;
binomial_lupmf;(ints n | ints N, reals theta);real;The log binomial probability mass of n successes in N trials given\nchance of success theta dropping constant additive terms\n;
binomial_cdf;(ints n | ints N, reals theta);real;The binomial cumulative distribution function of n successes in N\ntrials given chance of success theta\n;
binomial_lcdf;(ints n | ints N, reals theta);real;The log of the binomial cumulative distribution function of n\nsuccesses in N trials given chance of success theta\n;
binomial_lccdf;(ints n | ints N, reals theta);real;The log of the binomial complementary cumulative distribution function\nof n successes in N trials given chance of success theta\n;
binomial_rng;(ints N, reals theta);R;Generate a binomial variate with N trials and chance of success theta\nmay only be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
binomial_logit;~;real;Increment target log probability density with `binomial_logit_lupmf(n | N, alpha)`.;
binomial_logit_lpmf;(ints n | ints N, reals alpha);real;The log binomial probability mass of n successes in N trials given\nlogit-scaled chance of success alpha\n;
binomial_logit_lupmf;(ints n | ints N, reals alpha);real;The log binomial probability mass of n successes in N trials given\nlogit-scaled chance of success alpha dropping constant additive terms\n;
binomial_logit_glm;~;real;{{< since 2.34 >}};
binomial_logit_glm_lpmf;(int n | int N, matrix x, real alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)`.\n;
binomial_logit_glm_lupmf;(int n | int N, matrix x, real alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
binomial_logit_glm_lpmf;(int n | int N, matrix x, vector alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)`.\n;
binomial_logit_glm_lupmf;(int n | int N, matrix x, vector alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
binomial_logit_glm_lpmf;(array[] int n | array[] int N, row_vector x, real alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)`.\n;
binomial_logit_glm_lupmf;(array[] int n | array[] int N, row_vector x, real alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
binomial_logit_glm_lpmf;(array[] int n | array[] int N, row_vector x, vector alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)`.\n;
binomial_logit_glm_lupmf;(array[] int n | array[] int N, row_vector x, vector alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
binomial_logit_glm_lpmf;(array[] int n | array[] int N, matrix x, real alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)`.\n;
binomial_logit_glm_lupmf;(array[] int n | array[] int N, matrix x, real alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
binomial_logit_glm_lpmf;(array[] int n | array[] int N, matrix x, vector alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)`.\n;
binomial_logit_glm_lupmf;(array[] int n | array[] int N, matrix x, vector alpha, vector beta);real;The log binomial probability mass of n given N trials and chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
beta_binomial;~;real;Increment target log probability density with `beta_binomial_lupmf(n | N, alpha, beta)`.;
beta_binomial_lpmf;(ints n | ints N, reals alpha, reals beta);real;The log beta-binomial probability mass of n successes in N trials\ngiven prior success count (plus one) of alpha and prior failure count\n(plus one) of beta\n;
beta_binomial_lupmf;(ints n | ints N, reals alpha, reals beta);real;The log beta-binomial probability mass of n successes in N trials\ngiven prior success count (plus one) of alpha and prior failure count\n(plus one) of beta dropping constant additive terms\n;
beta_binomial_cdf;(ints n | ints N, reals alpha, reals beta);real;The beta-binomial cumulative distribution function of n successes in N\ntrials given prior success count (plus one) of alpha and prior failure\ncount (plus one) of beta\n;
beta_binomial_lcdf;(ints n | ints N, reals alpha, reals beta);real;The log of the beta-binomial cumulative distribution function of n\nsuccesses in N trials given prior success count (plus one) of alpha\nand prior failure count (plus one) of beta\n;
beta_binomial_lccdf;(ints n | ints N, reals alpha, reals beta);real;The log of the beta-binomial complementary cumulative distribution\nfunction of n successes in N trials given prior success count (plus\none) of alpha and prior failure count (plus one) of beta\n;
beta_binomial_rng;(ints N, reals alpha, reals beta);R;Generate a beta-binomial variate with N trials, prior success count\n(plus one) of alpha, and prior failure count (plus one) of beta may\nonly be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
hypergeometric;~;real;Increment target log probability density with `hypergeometric_lupmf(n | N, a, b)`.;
hypergeometric_lpmf;(int n | int N, int a, int b);real;The log hypergeometric probability mass of n successes in N trials\ngiven total success count of a and total failure count of b\n;
hypergeometric_lupmf;(int n | int N, int a, int b);real;The log hypergeometric probability mass of n successes in N trials\ngiven total success count of a and total failure count of b dropping constant\nadditive terms\n;
hypergeometric_rng;(int N, int a, int2 b);int;Generate a hypergeometric variate with N trials, total success count\nof a, and total failure count of b may only be used in transformed data and\ngenerated quantities blocks\n;
categorical;~;real;dropping constant additive terms.;
categorical_logit;~;real;Increment target log probability density with `categorical_logit_lupmf(y | beta)`.;
categorical_lpmf;(ints y | vector theta);real;The log categorical probability mass function with outcome(s) y in\n$1:N$ given $N$-vector of outcome probabilities theta. The parameter\ntheta must have non-negative entries that sum to one, but it need not\nbe a variable declared as a simplex.\n;
categorical_lupmf;(ints y | vector theta);real;The log categorical probability mass function with outcome(s) y in\n$1:N$ given $N$-vector of outcome probabilities theta dropping constant\nadditive terms. The parameter theta must have non-negative entries that sum\nto one, but it need not be a variable declared as a simplex.\n;
categorical_logit_lpmf;(ints y | vector beta);real;The log categorical probability mass function with outcome(s) y in\n$1:N$ given log-odds of outcomes beta.\n;
categorical_logit_lupmf;(ints y | vector beta);real;The log categorical probability mass function with outcome(s) y in\n$1:N$ given log-odds of outcomes beta dropping constant additive terms.\n;
categorical_rng;(vector theta);int;Generate a categorical variate with $N$-simplex distribution parameter\ntheta may only be used in transformed data and generated quantities blocks\n;
categorical_logit_rng;(vector beta);int;Generate a categorical variate with outcome in range $1:N$ from\nlog-odds vector beta may only be used in transformed data and generated\nquantities blocks\n;
categorical_logit_glm;~;real;Increment target log probability density with `categorical_logit_glm_lupmf(y | x, alpha, beta)`.;
categorical_logit_glm_lpmf;(int y | row_vector x, vector alpha, matrix beta);real;The log categorical probability mass function with outcome `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`.\n;
categorical_logit_glm_lupmf;(int y | row_vector x, vector alpha, matrix beta);real;The log categorical probability mass function with outcome `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`\ndropping constant additive terms.\n;
categorical_logit_glm_lpmf;(int y | matrix x, vector alpha, matrix beta);real;The log categorical probability mass function with outcomes `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`.\n;
categorical_logit_glm_lupmf;(int y | matrix x, vector alpha, matrix beta);real;The log categorical probability mass function with outcomes `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`\ndropping constant additive terms.\n;
categorical_logit_glm_lpmf;(array[] int y | row_vector x, vector alpha, matrix beta);real;The log categorical probability mass function with outcomes `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`.\n;
categorical_logit_glm_lupmf;(array[] int y | row_vector x, vector alpha, matrix beta);real;The log categorical probability mass function with outcomes `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`\ndropping constant additive terms.\n;
categorical_logit_glm_lpmf;(array[] int y | matrix x, vector alpha, matrix beta);real;The log categorical probability mass function with outcomes `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`.\n;
categorical_logit_glm_lupmf;(array[] int y | matrix x, vector alpha, matrix beta);real;The log categorical probability mass function with outcomes `y` in\n$1:N$ given $N$-vector of log-odds of outcomes `alpha + x * beta`\ndropping constant additive terms.\n;
discrete_range;~;real;dropping constant additive terms.;
discrete_range_lpmf;(ints y | ints l, ints u);real;The log probability mass function with outcome(s) y in $l:u$.\n;
discrete_range_lupmf;(ints y | ints l, ints u);real;The log probability mass function with outcome(s) y in $l:u$\ndropping constant additive terms.\n;
discrete_range_cdf;(ints y | ints l, ints u);real;The discrete range cumulative distribution function\nfor the given y, lower and upper bounds.\n;
discrete_range_lcdf;(ints y | ints l, ints u);real;The log of the discrete range cumulative distribution function\nfor the given y, lower and upper bounds.\n;
discrete_range_lccdf;(ints y | ints l, ints u);real;The log of the discrete range complementary cumulative distribution function\nfor the given y, lower and upper bounds.\n;
discrete_range_rng;(ints l, ints u);int;Generate a discrete variate between the given lower and upper bounds\nmay only be used in transformed data and generated quantities blocks.\n;
ordered_logistic;~;real;Increment target log probability density with `ordered_logistic_lupmf(y | x, beta, c)`.;
ordered_logistic_lpmf;(ints k | vector eta, vectors c);real;The log ordered logistic probability mass of k given linear predictors\n`eta`, and cutpoints `c`.\n;
ordered_logistic_lupmf;(ints k | vector eta, vectors c);real;The log ordered logistic probability mass of k given linear predictors\n`eta`, and cutpoints `c` dropping constant additive terms.\n;
ordered_logistic_rng;(real eta, vector c);int;Generate an ordered logistic variate with linear predictor `eta` and\ncutpoints `c` may only be used in transformed data and generated quantities blocks\n;
ordered_logistic_glm_lpmf;(int y | row_vector x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors `x * beta`, and cutpoints c.\nThe cutpoints `c` must be ordered.\n;
ordered_logistic_glm_lupmf;(int y | row_vector x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors\n`x * beta`, and cutpoints c dropping constant additive terms. The cutpoints\n`c` must be ordered.\n;
ordered_logistic_glm_lpmf;(int y | matrix x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors `x * beta`, and cutpoints c.\nThe cutpoints `c` must be ordered.\n;
ordered_logistic_glm_lupmf;(int y | matrix x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors\n`x * beta`, and cutpoints c dropping constant additive terms. The cutpoints\n`c` must be ordered.\n;
ordered_logistic_glm_lpmf;(array[] int y | row_vector x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors `x * beta`, and cutpoints c.\nThe cutpoints `c` must be ordered.\n;
ordered_logistic_glm_lupmf;(array[] int y | row_vector x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors\n`x * beta`, and cutpoints c dropping constant additive terms. The cutpoints\n`c` must be ordered.\n;
ordered_logistic_glm_lpmf;(array[] int y | matrix x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors\n`x * beta`, and cutpoints c. The cutpoints `c` must be ordered.\n;
ordered_logistic_glm_lupmf;(array[] int y | matrix x, vector beta, vector c);real;The log ordered logistic probability mass of y, given linear predictors\n`x * beta`, and cutpoints c dropping constant additive terms. The cutpoints `c`\nmust be ordered.\n;
ordered_probit;~;real;Increment target log probability density with `ordered_probit_lupmf(k | eta, c)`.;
ordered_probit_lpmf;(ints k | vector eta, vectors c);real;The log ordered probit probability mass of k given linear predictors\neta, and cutpoints c.\n;
ordered_probit_lupmf;(ints k | vector eta, vectors c);real;The log ordered probit probability mass of k given linear predictors\neta, and cutpoints c dropping constant additive terms.\n;
ordered_probit_lpmf;(ints k | real eta, vectors c);real;The log ordered probit probability mass of k given linear predictor eta, and cutpoints c.\n;
ordered_probit_lupmf;(ints k | real eta, vectors c);real;The log ordered probit probability mass of k given linear predictor eta, and cutpoints c dropping constant additive terms.\n;
ordered_probit_rng;(real eta, vector c);int;Generate an ordered probit variate with linear predictor eta and\ncutpoints c may only be used in transformed data and generated quantities blocks\n;
operator+=;(T x, U y);void;`x += y` is equivalent to `x = x + y`.  Defined for all types `T` and `U`\nwhere `T = T + U` is well formed.\n;
operator-=;(T x, U y);void;`x -= y` is equivalent to `x = x - y`.  Defined for all types `T` and `U`\nwhere `T = T - U` is well formed.\n;
operator*=;(T x, U y);void;`x *= y` is equivalent to `x = x * y`.  Defined for all types `T` and `U`\nwhere `T = T * U` is well formed.\n;
operator/=;(T x, U y);void;`x /= y` is equivalent to `x = x / y`.  Defined for all types `T` and `U`\nwhere `T = T / U` is well formed.\n;
operator.*=;(T x, U y);void;`x .*= y` is equivalent to `x = x .* y`.  Defined for all types `T` and `U`\nwhere `T = T .* U` is well formed.\n;
operator./=;(T x, U y);void;`x ./= y` is equivalent to `x = x ./ y`.  Defined for all types `T` and `U`\nwhere `T = T ./ U` is well formed.\n;
dirichlet;~;real;Increment target log probability density with `dirichlet_lupdf(theta | alpha)`.;
dirichlet_lpdf;(vectors theta | vectors alpha);real;The log of the Dirichlet density for simplex(es) `theta` given prior counts\n(plus one) `alpha`\n;
dirichlet_lupdf;(vectors theta | vectors alpha);real;The log of the Dirichlet density for simplex(es) `theta` given prior counts\n(plus one) `alpha` dropping constant additive terms\n;
dirichlet_rng;(vector alpha);vector;Generate a Dirichlet variate with prior counts (plus one) `alpha` may\nonly be used in transformed data and generated quantities blocks\n;
csr_extract_w;(matrix a);vector;Return non-zero values in matrix a see section [compressed row storage](#CSR).\n;
csr_extract_v;(matrix a);array[] int;Return column indices for values in `csr_extract_w(a)` see\n[compressed row storage](#CSR).\n;
csr_extract_u;(matrix a);array[] int;Return array of row starting indices for entries in `csr_extract_w(a)`\nfollowed by the size of `csr_extract_w(a)` plus one see section\n[compressed row storage](#CSR).\n;
csr_extract;(matrix a);tuple(vector, array[] int, array[] int);Return all three components of the CSR representation of the matrix `a` see\nsection [compressed row storage](#CSR).\nThis function is equivalent to `(csr_extract_w(a), csr_extract_v(a), csr_extract_u(a))`.\n;
csr_to_dense_matrix;(int m, int n, vector w, array[] int v, array[] int u);matrix;Return dense $\text{m} \times \text{n}$ matrix with non-zero matrix\nentries w, column indices v, and row starting indices u the vector w\nand array v must be the same size (corresponding to the total number of\nnonzero entries in the matrix), array v must have index values bounded\nby m, array u must have length equal to m + 1 and contain index values\nbounded by the number of nonzeros (except for the last entry, which must\nbe equal to the number of nonzeros plus one). See section\n[compressed row storage](#CSR) for more details.\n;
csr_matrix_times_vector;(int m, int n, vector w, array[] int v, array[] int u, vector b);vector;Multiply the $\text{m} \times \text{n}$ matrix represented by values\nw, column indices v, and row start indices u by the vector b see\n[compressed row storage](#CSR).\n;
num_elements;(vector x);int;The total number of elements in the vector x (same as function `rows`)\n;
num_elements;(row_vector x);int;The total number of elements in the vector x (same as function `cols`)\n;
num_elements;(matrix x);int;The total number of elements in the matrix x. For example, if `x` is a\n$5 \times 3$ matrix, then `num_elements(x)` is 15\n;
rows;(vector x);int;The number of rows in the vector x\n;
rows;(row_vector x);int;The number of rows in the row vector x, namely 1\n;
rows;(matrix x);int;The number of rows in the matrix x\n;
cols;(vector x);int;The number of columns in the vector x, namely 1\n;
cols;(row_vector x);int;The number of columns in the row vector x\n;
cols;(matrix x);int;The number of columns in the matrix x\n;
size;(vector x);int;The size of `x`, i.e., the number of elements\n;
size;(row_vector x);int;The size of `x`, i.e., the number of elements\n;
size;(matrix x);int;The size of the matrix `x`.  For example, if `x` is a\n$5 \times 3$ matrix, then `size(x)` is 15\n;
operator-;(vector x);vector;The negation of the vector x.\n;
operator-;(row_vector x);row_vector;The negation of the row vector x.\n;
operator-;(matrix x);matrix;The negation of the matrix x.\n;
operator-;(T x);T;Vectorized version of `operator-`. If `T x` is a (possibly nested) array of\nmatrix types, `-x` is the same shape array where each individual value is negated.\n;
operator+;(vector x, vector y);vector;The sum of the vectors x and y.\n;
operator+;(row_vector x, row_vector y);row_vector;The sum of the row vectors x and y.\n;
operator+;(matrix x, matrix y);matrix;The sum of the matrices x and y\n;
operator-;(vector x, vector y);vector;The difference between the vectors x and y.\n;
operator-;(row_vector x, row_vector y);row_vector;The difference between the row vectors x and y\n;
operator-;(matrix x, matrix y);matrix;The difference between the matrices x and y\n;
operator*;(real x, vector y);vector;The product of the scalar x and vector y\n;
operator*;(real x, row_vector y);row_vector;The product of the scalar x and the row vector y\n;
operator*;(real x, matrix y);matrix;The product of the scalar x and the matrix y\n;
operator*;(vector x, real y);vector;The product of the scalar y and vector x\n;
operator*;(vector x, row_vector y);matrix;The product of the vector x and row vector y\n;
operator*;(row_vector x, real y);row_vector;The product of the scalar y and row vector x\n;
operator*;(row_vector x, vector y);real;The product of the row vector x and vector y\n;
operator*;(row_vector x, matrix y);row_vector;The product of the row vector x and matrix y\n;
operator*;(matrix x, real y);matrix;The product of the scalar y and matrix x\n;
operator*;(matrix x, vector y);vector;The product of the matrix x and vector y\n;
operator*;(matrix x, matrix y);matrix;The product of the matrices x and y\n;
operator+;(vector x, real y);vector;The result of adding y to every entry in the vector x\n;
operator+;(real x, vector y);vector;The result of adding x to every entry in the vector y\n;
operator+;(row_vector x, real y);row_vector;The result of adding y to every entry in the row vector x\n;
operator+;(real x, row_vector y);row_vector;The result of adding x to every entry in the row vector y\n;
operator+;(matrix x, real y);matrix;The result of adding y to every entry in the matrix x\n;
operator+;(real x, matrix y);matrix;The result of adding x to every entry in the matrix y\n;
operator-;(vector x, real y);vector;The result of subtracting y from every entry in the vector x\n;
operator-;(real x, vector y);vector;The result of adding x to every entry in the negation of the vector y\n;
operator-;(row_vector x, real y);row_vector;The result of subtracting y from every entry in the row vector x\n;
operator-;(real x, row_vector y);row_vector;The result of adding x to every entry in the negation of the row\nvector y\n;
operator-;(matrix x, real y);matrix;The result of subtracting y from every entry in the matrix x\n;
operator-;(real x, matrix y);matrix;The result of adding x to every entry in negation of the matrix y\n;
operator/;(vector x, real y);vector;The result of dividing each entry in the vector x by y\n;
operator/;(row_vector x, real y);row_vector;The result of dividing each entry in the row vector x by y\n;
operator/;(matrix x, real y);matrix;The result of dividing each entry in the matrix x by y\n;
operator';(matrix x);matrix;The transpose of the matrix x, written as `x'`\n;
operator';(vector x);row_vector;The transpose of the vector x, written as `x'`\n;
operator';(row_vector x);vector;The transpose of the row vector x, written as `x'`\n;
operator.*;(vector x, vector y);vector;The elementwise product of y and x\n;
operator.*;(row_vector x, row_vector y);row_vector;The elementwise product of y and x\n;
operator.*;(matrix x, matrix y);matrix;The elementwise product of y and x\n;
operator./;(vector x, vector y);vector;The elementwise quotient of y and x\n;
operator./;(vector x, real y);vector;The elementwise quotient of y and x\n;
operator./;(real x, vector y);vector;The elementwise quotient of y and x\n;
operator./;(row_vector x, row_vector y);row_vector;The elementwise quotient of y and x\n;
operator./;(row_vector x, real y);row_vector;The elementwise quotient of y and x\n;
operator./;(real x, row_vector y);row_vector;The elementwise quotient of y and x\n;
operator./;(matrix x, matrix y);matrix;The elementwise quotient of y and x\n;
operator./;(matrix x, real y);matrix;The elementwise quotient of y and x\n;
operator./;(real x, matrix y);matrix;The elementwise quotient of y and x\n;
operator.^;(vector x, vector y);vector;The elementwise power of y and x\n;
operator.^;(vector x, real y);vector;The elementwise power of y and x\n;
operator.^;(real x, vector y);vector;The elementwise power of y and x\n;
operator.^;(row_vector x, row_vector y);row_vector;The elementwise power of y and x\n;
operator.^;(row_vector x, real y);row_vector;The elementwise power of y and x\n;
operator.^;(real x, row_vector y);row_vector;The elementwise power of y and x\n;
operator.^;(matrix x, matrix y);matrix;The elementwise power of y and x\n;
operator.^;(matrix x, real y);matrix;The elementwise power of y and x\n;
operator.^;(real x, matrix y);matrix;The elementwise power of y and x\n;
dot_product;(vector x, vector y);real;The dot product of x and y\n;
dot_product;(vector x, row_vector y);real;The dot product of x and y\n;
dot_product;(row_vector x, vector y);real;The dot product of x and y\n;
dot_product;(row_vector x, row_vector y);real;The dot product of x and y\n;
columns_dot_product;(vector x, vector y);row_vector;The dot product of the columns of x and y\n;
columns_dot_product;(row_vector x, row_vector y);row_vector;The dot product of the columns of x and y\n;
columns_dot_product;(matrix x, matrix y);row_vector;The dot product of the columns of x and y\n;
rows_dot_product;(vector x, vector y);vector;The dot product of the rows of x and y\n;
rows_dot_product;(row_vector x, row_vector y);vector;The dot product of the rows of x and y\n;
rows_dot_product;(matrix x, matrix y);vector;The dot product of the rows of x and y\n;
dot_self;(vector x);real;The dot product of the vector x with itself\n;
dot_self;(row_vector x);real;The dot product of the row vector x with itself\n;
columns_dot_self;(vector x);row_vector;The dot product of the columns of x with themselves\n;
columns_dot_self;(row_vector x);row_vector;The dot product of the columns of x with themselves\n;
columns_dot_self;(matrix x);row_vector;The dot product of the columns of x with themselves\n;
rows_dot_self;(vector x);vector;The dot product of the rows of x with themselves\n;
rows_dot_self;(row_vector x);vector;The dot product of the rows of x with themselves\n;
rows_dot_self;(matrix x);vector;The dot product of the rows of x with themselves\n;
tcrossprod;(matrix x);matrix;The product of x postmultiplied by its own transpose, similar to the\ntcrossprod(x) function in R. The result is a symmetric matrix\n$\text{x}\,\text{x}^{\top}$.\n;
crossprod;(matrix x);matrix;The product of x premultiplied by its own transpose, similar to the\ncrossprod(x) function in R. The result is a symmetric matrix\n$\text{x}^{\top}\,\text{x}$.\nThe following functions all provide shorthand forms for common\nexpressions, which are also much more efficient.\n;
quad_form;(matrix A, matrix B);matrix;The quadratic form, i.e., `B' * A * B`.\n;
quad_form;(matrix A, vector B);real;The quadratic form, i.e., `B' * A * B`.\n;
quad_form_diag;(matrix m, vector v);matrix;The quadratic form using the column vector v as a diagonal matrix,\ni.e., `diag_matrix(v) * m * diag_matrix(v)`.\n;
quad_form_diag;(matrix m, row_vector rv);matrix;The quadratic form using the row vector rv as a diagonal matrix, i.e.,\n`diag_matrix(rv) * m * diag_matrix(rv)`.\n;
quad_form_sym;(matrix A, matrix B);matrix;Similarly to quad_form, gives `B' * A * B`, but additionally checks if\nA is symmetric and ensures that the result is also symmetric.\n;
quad_form_sym;(matrix A, vector B);real;Similarly to quad_form, gives `B' * A * B`, but additionally checks if\nA is symmetric and ensures that the result is also symmetric.\n;
trace_quad_form;(matrix A, matrix B);real;The trace of the quadratic form, i.e., `trace(B' * A * B)`.\n;
trace_gen_quad_form;(matrix D,matrix A, matrix B);real;The trace of a generalized quadratic form, i.e., `trace(D * B' * A *\nB).`\n;
multiply_lower_tri_self_transpose;(matrix x);matrix;The product of the lower triangular portion of x (including the\ndiagonal) times its own transpose that is, if `L` is a matrix of the\nsame dimensions as x with `L(m,n)` equal to `x(m,n)` for $\text{n}\n\leq \text{m}$ and `L(m,n)` equal to 0 if $\text{n} > \text{m}$, the\nresult is the symmetric matrix $\text{L}\,\text{L}^{\top}$. This is a\nspecialization of tcrossprod(x) for lower-triangular matrices. The\ninput matrix does not need to be square.\n;
diag_pre_multiply;(vector v, matrix m);matrix;Return the product of the diagonal matrix formed from the vector v and\nthe matrix m, i.e., `diag_matrix(v) * m`.\n;
diag_pre_multiply;(row_vector rv, matrix m);matrix;Return the product of the diagonal matrix formed from the vector rv\nand the matrix m, i.e., `diag_matrix(rv) * m`.\n;
diag_post_multiply;(matrix m, vector v);matrix;Return the product of the matrix m and the diagonal matrix formed from\nthe vector v, i.e., `m * diag_matrix(v)`.\n;
diag_post_multiply;(matrix m, row_vector rv);matrix;Return the product of the matrix `m` and the diagonal matrix formed\nfrom the the row vector `rv`, i.e., `m * diag_matrix(rv)`.\n;
log_sum_exp;(vector x);real;The natural logarithm of the sum of the exponentials of the elements\nin x\n;
log_sum_exp;(row_vector x);real;The natural logarithm of the sum of the exponentials of the elements\nin x\n;
log_sum_exp;(matrix x);real;The natural logarithm of the sum of the exponentials of the elements\nin x\n;
min;(vector x);real;The minimum value in x, or $+\infty$ if x is empty\n;
min;(row_vector x);real;The minimum value in x, or $+\infty$ if x is empty\n;
min;(matrix x);real;The minimum value in x, or $+\infty$ if x is empty\n;
max;(vector x);real;The maximum value in x, or $-\infty$ if x is empty\n;
max;(row_vector x);real;The maximum value in x, or $-\infty$ if x is empty\n;
max;(matrix x);real;The maximum value in x, or $-\infty$ if x is empty\n;
sum;(vector x);real;The sum of the values in x, or 0 if x is empty\n;
sum;(row_vector x);real;The sum of the values in x, or 0 if x is empty\n;
sum;(matrix x);real;The sum of the values in x, or 0 if x is empty\n;
prod;(vector x);real;The product of the values in x, or 1 if x is empty\n;
prod;(row_vector x);real;The product of the values in x, or 1 if x is empty\n;
prod;(matrix x);real;The product of the values in x, or 1 if x is empty\n;
mean;(vector x);real;The sample mean of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
mean;(row_vector x);real;The sample mean of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
mean;(matrix x);real;The sample mean of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
variance;(vector x);real;The sample variance of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
variance;(row_vector x);real;The sample variance of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
variance;(matrix x);real;The sample variance of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
sd;(vector x);real;The sample standard deviation of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
sd;(row_vector x);real;The sample standard deviation of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
sd;(matrix x);real;The sample standard deviation of the values in x see section\n[array reductions](array_operations.qmd#array-reductions) for details.\n;
quantile;(data vector x, data real p);real;The p-th quantile of x\n;
quantile;(data vector x, data array[] real p);array[] real;An array containing the quantiles of x given by the array of probabilities p\n;
quantile;(data row_vector x, data real p);real;The p-th quantile of x\n;
quantile;(data row_vector x, data array[] real p);array[] real;An array containing the quantiles of x given by the array of probabilities p\n;
rep_vector;(real x, int m);vector;Return the size m (column) vector consisting of copies of x.\n;
rep_row_vector;(real x, int n);row_vector;Return the size n row vector consisting of copies of x.\n;
rep_matrix;(real x, int m, int n);matrix;Return the m by n matrix consisting of copies of x.\n;
rep_matrix;(vector v, int n);matrix;Return the m by n matrix consisting of n copies of the (column) vector\nv of size m.\n;
rep_matrix;(row_vector rv, int m);matrix;Return the m by n matrix consisting of m copies of the row vector rv\nof size n.\nUnlike the situation with array broadcasting (see section\n[array broadcasting](array_operations.qmd#array-broadcasting)), where there is a distinction between\ninteger and real arguments, the following two statements produce the\nsame result for vector broadcasting  row vector and matrix\nbroadcasting behave similarly.\n```stan\n vector[3] x\n x = rep_vector(1, 3)\n x = rep_vector(1.0, 3)\n```\nThere are no integer vector or matrix types, so integer values are\nautomatically promoted.\n;
symmetrize_from_lower_tri;(matrix A);matrix;Construct a symmetric matrix from the lower triangle of A.\n;
add_diag;(matrix m, row_vector d);matrix;Add row_vector `d` to the diagonal of matrix `m`.\n;
add_diag;(matrix m, vector d);matrix;Add vector `d` to the diagonal of matrix `m`.\n;
add_diag;(matrix m, real d);matrix;Add scalar `d` to every diagonal element of matrix `m`.\n;
diagonal;(matrix x);vector;The diagonal of the matrix x\n;
diag_matrix;(vector x);matrix;The diagonal matrix with diagonal x\nAlthough the `diag_matrix` function is available, it is unlikely to\never show up in an efficient Stan program.  For example, rather than\nconverting a diagonal to a full matrix for use as a covariance matrix,\n```stan\n y ~ multi_normal(mu, diag_matrix(square(sigma)))\n```\nit is much more efficient to just use a univariate normal, which\nproduces the same density,\n```stan\n y ~ normal(mu, sigma)\n```\nRather than writing `m * diag_matrix(v)` where `m` is a matrix and `v`\nis a vector, it is much more efficient to write `diag_post_multiply(m,\nv)` (and similarly for pre-multiplication). By the same token, it is\nbetter to use `quad_form_diag(m, v)` rather than `quad_form(m,\ndiag_matrix(v))`.\n;
identity_matrix;(int k);matrix;Create an identity matrix of size $k \times k$\n;
linspaced_array;(int n, data real lower, data real upper);array[] real;Create a real array of length `n` of equidistantly-spaced elements between `lower` and `upper`\n;
linspaced_int_array;(int n, int lower, int upper);array[] real;Create a regularly spaced, increasing integer array of length `n` between `lower` and `upper`, inclusively.\nIf `(upper - lower) / (n - 1)` is less than one, repeat each output `(n - 1) / (upper - lower)` times.\nIf neither `(upper - lower) / (n - 1)` or `(n - 1) / (upper - lower)` are integers, `upper` is reduced until one of these is true.\n;
linspaced_vector;(int n, data real lower, data real upper);vector;Create an `n`-dimensional vector of equidistantly-spaced elements between `lower` and `upper`\n;
linspaced_row_vector;(int n, data real lower, data real upper);row_vector;Create an `n`-dimensional row-vector of equidistantly-spaced elements between `lower` and `upper`\n;
one_hot_int_array;(int n, int k);array[] int;Create a one-hot encoded int array of length `n` with `array[k] = 1`\n;
one_hot_array;(int n, int k);array[] real;Create a one-hot encoded real array of length `n` with `array[k] = 1`\n;
one_hot_vector;(int K, int k);vector;Create an `n`-dimensional one-hot encoded vector with `vector[k] = 1`\n;
one_hot_row_vector;(int n, int k);row_vector;Create an `n`-dimensional one-hot encoded row-vector  with `row_vector[k] = 1`\n;
ones_int_array;(int n);array[] int;Create an int array of length `n` of all ones\n;
ones_array;(int n);array[] real;Create a real array of length `n` of all ones\n;
ones_vector;(int n);vector;Create an `n`-dimensional vector of all ones\n;
ones_row_vector;(int n);row_vector;Create an `n`-dimensional row-vector of all ones\n;
zeros_int_array;(int n);array[] int;Create an int array of length `n` of all zeros\n;
zeros_array;(int n);array[] real;Create a real array of length `n` of all zeros\n;
zeros_row_vector;(int n);vector;Create an `n`-dimensional vector of all zeros\n;
zeros_row_vector;(int n);row_vector;Create an `n`-dimensional row-vector of all zeros\n;
uniform_simplex;(int n);vector;Create an `n`-dimensional simplex with elements `vector[i] = 1 / n` for all $i \in 1, \dots, n$\n;
col;(matrix x, int n);vector;The n-th column of matrix x\n;
row;(matrix x, int m);row_vector;The m-th row of matrix x\nThe `row` function is special in that it may be used as an lvalue in\nan assignment statement (i.e., something to which a value may be\nassigned).  The row function is also special in that the indexing\nnotation `x[m]` is just an alternative way of writing `row(x,m)`.  The\n`col` function may **not**, be used as an lvalue, nor is there an\nindexing based shorthand for it.\n;
block;(matrix x, int i, int j, int n_rows, int n_cols);matrix;Return the submatrix of x that starts at row i and column j and\nextends n_rows rows and n_cols columns.\nThe sub-row and sub-column operations may be used to extract a slice\nof row or column from a matrix\n;
sub_col;(matrix x, int i, int j, int n_rows);vector;Return the sub-column of x that starts at row i and column j and\nextends n_rows rows and 1 column.\n;
sub_row;(matrix x, int i, int j, int n_cols);row_vector;Return the sub-row of x that starts at row i and column j and extends\n1 row and n_cols columns.\n;
head;(vector v, int n);vector;Return the vector consisting of the first n elements of v.\n;
head;(row_vector rv, int n);row_vector;Return the row vector consisting of the first n elements of rv.\n;
head;(array[] T sv, int n);array[] T;Return the array consisting of the first n elements of sv applies to\nup to three-dimensional arrays containing any type of elements `T`.\n;
tail;(vector v, int n);vector;Return the vector consisting of the last n elements of v.\n;
tail;(row_vector rv, int n);row_vector;Return the row vector consisting of the last n elements of rv.\n;
tail;(array[] T sv, int n);array[] T;Return the array consisting of the last n elements of sv applies to\nup to three-dimensional arrays containing any type of elements `T`.\n;
segment;(vector v, int i, int n);vector;Return the vector consisting of the n elements of v starting at i\ni.e., elements i through through i + n - 1.\n;
segment;(row_vector rv, int i, int n);row_vector;Return the row vector consisting of the n elements of rv starting at\ni i.e., elements i through through i + n - 1.\n;
segment;(array[] T sv, int i, int n);array[] T;Return the array consisting of the n elements of sv starting at i\ni.e., elements i through through i + n - 1. Applies to up to\nthree-dimensional arrays containing any type of elements `T`.\n;
append_col;(matrix x, matrix y);matrix;Combine matrices x and y by column. The matrices must have the same\nnumber of rows.\n;
append_col;(matrix x, vector y);matrix;Combine matrix x and vector y by column. The matrix and the vector\nmust have the same number of rows.\n;
append_col;(vector x, matrix y);matrix;Combine vector x and matrix y by column. The vector and the matrix\nmust have the same number of rows.\n;
append_col;(vector x, vector y);matrix;Combine vectors x and y by column. The vectors must have the same\nnumber of rows.\n;
append_col;(row_vector x, row_vector y);row_vector;Combine row vectors x and y of any size into another row vector by appending y\nto the end of x.\n;
append_col;(real x, row_vector y);row_vector;Append x to the front of y, returning another row vector.\n;
append_col;(row_vector x, real y);row_vector;Append y to the end of x, returning another row vector.\n;
append_row;(matrix x, matrix y);matrix;Combine matrices x and y by row. The matrices must have the same\nnumber of columns.\n;
append_row;(matrix x, row_vector y);matrix;Combine matrix x and row vector y by row. The matrix and the row\nvector must have the same number of columns.\n;
append_row;(row_vector x, matrix y);matrix;Combine row vector x and matrix y by row. The row vector and the\nmatrix must have the same number of columns.\n;
append_row;(row_vector x, row_vector y);matrix;Combine row vectors x and y by row. The row vectors must have the same\nnumber of columns.\n;
append_row;(vector x, vector y);vector;Concatenate vectors x and y of any size into another vector.\n;
append_row;(real x, vector y);vector;Append x to the top of y, returning another vector.\n;
append_row;(vector x, real y);vector;Append y to the bottom of x, returning another vector.\n;
softmax;(vector x);vector;The softmax of x\n;
log_softmax;(vector x);vector;The natural logarithm of the softmax of x\n;
cumulative_sum;(array[] int x);array[] int;The cumulative sum of x\n;
cumulative_sum;(array[] real x);array[] real;The cumulative sum of x\n;
cumulative_sum;(vector v);vector;The cumulative sum of v\n;
cumulative_sum;(row_vector rv);row_vector;The cumulative sum of rv\n;
operator/;(row_vector b, matrix A);row_vector;The right division of b by A equivalently `b * inverse(A)`\n;
operator/;(matrix B, matrix A);matrix;The right division of B by A equivalently `B * inverse(A)`\n;
operator\;(matrix A, vector b);vector;The left division of A by b equivalently `inverse(A) * b`\n;
operator\;(matrix A, matrix B);matrix;The left division of A by B equivalently `inverse(A) * B`\n;
mdivide_left_tri_low;(matrix A, vector b);vector;The left division of b by a lower-triangular view of A algebraically\nequivalent to the less efficient and stable form `inverse(tri(A)) *\nb`, where `tri(A)` is the lower-triangular portion of A with the\nabove-diagonal entries set to zero.\n;
mdivide_left_tri_low;(matrix A, matrix B);matrix;The left division of B by a triangular view of A algebraically\nequivalent to the less efficient and stable form `inverse(tri(A)) *\nB`, where `tri(A)` is the lower-triangular portion of A with the\nabove-diagonal entries set to zero.\n;
mdivide_right_tri_low;(row_vector b, matrix A);row_vector;The right division of b by a triangular view of A algebraically\nequivalent to the less efficient and stable form `b *\ninverse(tri(A))`, where `tri(A)` is the lower-triangular portion of A\nwith the above-diagonal entries set to zero.\n;
mdivide_right_tri_low;(matrix B, matrix A);matrix;The right division of B by a triangular view of A algebraically\nequivalent to the less efficient and stable form `B *\ninverse(tri(A))`, where `tri(A)` is the lower-triangular portion of A\nwith the above-diagonal entries set to zero.\n;
mdivide_left_spd;(matrix A, vector b);matrix;The left division of b by the symmetric, positive-definite matrix A\nalgebraically equivalent to the less efficient and stable form\n`inverse(A) * b`.\n;
mdivide_left_spd;(matrix A, matrix B);vector;The left division of B by the symmetric, positive-definite matrix A\nalgebraically equivalent to the less efficient and stable form\n`inverse(A) * B`.\n;
mdivide_right_spd;(row_vector b, matrix A);row_vector;The right division of b by the symmetric, positive-definite matrix A\nalgebraically equivalent to the less efficient and stable form\n`b *inverse(A)`.\n;
mdivide_right_spd;(matrix B, matrix A);matrix;The right division of B by the symmetric, positive-definite matrix A\nalgebraically equivalent to the less efficient and stable form\n`B * inverse(A)`.\n;
matrix_exp;(matrix A);matrix;The matrix exponential of A\n;
matrix_exp_multiply;(matrix A, matrix B);matrix;The multiplication of matrix exponential of A and matrix B\nalgebraically equivalent to the less efficient form `matrix_exp(A) * B`.\n;
scale_matrix_exp_multiply;(real t, matrix A, matrix B);matrix;The multiplication of matrix exponential of tA and matrix B\nalgebraically equivalent to the less efficient form `matrix_exp(t * A) * B`.\n;
matrix_power;(matrix A, int B);matrix;Matrix A raised to the power B.\n;
trace;(matrix A);real;The trace of A, or 0 if A is empty A is not required to be diagonal\n;
determinant;(matrix A);real;The determinant of A\n;
log_determinant;(matrix A);real;The log of the absolute value of the determinant of A\nThe log of the absolute value of the determinant of the symmetric, positive-definite matrix A.\n;
inverse;(matrix A);matrix;Compute the inverse of A\n;
inverse_spd;(matrix A);matrix;Compute the inverse of A where A is symmetric, positive definite. This version\nis faster and more arithmetically stable when the input is symmetric\nand positive definite.\n;
chol2inv;(matrix L);matrix;Compute the inverse of the matrix whose cholesky factorization is L.\nThat is, for $A = L L^T$, return $A^{-1}$.\n;
generalized_inverse;(matrix A);matrix;The generalized inverse of A\n;
eigenvalues;(matrix A);complex_vector;The complex-valued vector of eigenvalues of the matrix `A`. The eigenvalues are\nrepeated according to their algebraic multiplicity, so there are as many\neigenvalues as rows in the matrix. The eigenvalues are not sorted in any\nparticular order.\n;
eigenvectors;(matrix A);complex_matrix;The matrix with the complex-valued (column) eigenvectors of the matrix `A` in the\nsame order as returned by the function `eigenvalues`\n;
eigendecompose;(matrix A);tuple(complex_matrix, complex_vector);Return the matrix of (column) eigenvectors and vector of eigenvalues of the\nmatrix `A`. This function is equivalent to `(eigenvectors(A), eigenvalues(A))`\nbut with a lower computational cost due to the shared work between the two\nresults.\n;
eigenvalues_sym;(matrix A);vector;The vector of eigenvalues of a symmetric matrix `A` in ascending order\n;
eigenvectors_sym;(matrix A);matrix;The matrix with the (column) eigenvectors of symmetric matrix `A` in the\nsame order as returned by the function `eigenvalues_sym`\n;
eigendecompose_sym;(matrix A);tuple(matrix, vector);Return the matrix of (column) eigenvectors and vector of eigenvalues of the\nsymmetric matrix `A`. This function is equivalent to `(eigenvectors_sym(A),\neigenvalues_sym(A))` but with a lower computational cost due to the shared work\nbetween the two results.\nBecause multiplying an eigenvector by $-1$ results in an eigenvector,\neigenvectors returned by a decomposition are only identified up to a\nsign change.  In order to compare the eigenvectors produced by Stan's\neigendecomposition to others, signs may need to be normalized in some\nway, such as by fixing the sign of a component, or doing comparisons\nallowing a multiplication by $-1$.\nThe condition number of a symmetric matrix is defined to be the ratio\nof the largest eigenvalue to the smallest eigenvalue.  Large condition\nnumbers lead to difficulty in numerical algorithms such as computing\ninverses, and thus known as "ill conditioned."  The ratio can even be\ninfinite in the case of singular matrices (i.e., those with\neigenvalues of 0).\n;
qr_thin_Q;(matrix A);matrix;The orthogonal matrix in the thin QR decomposition of A, which implies\nthat the resulting matrix has the same dimensions as A\n;
qr_thin_R;(matrix A);matrix;The upper triangular matrix in the thin QR decomposition of A, which\nimplies that the resulting matrix is square with the same number of\ncolumns as A\n;
qr_thin;(matrix A);tuple(matrix, matrix);Returns both portions of the QR decomposition of A. The first element ("Q") is\nthe orthonormal matrix in the thin QR decomposition and the second element ("R")\nis upper triangular. This function is equivalent to `(qr_thin_Q(A),\nqr_thin_R(A))` but with a lower computational cost due to the shared work\nbetween the two results.\n;
qr_Q;(matrix A);matrix;The orthogonal matrix in the fat QR decomposition of A, which implies\nthat the resulting matrix is square with the same number of rows as A\n;
qr_R;(matrix A);matrix;The upper trapezoidal matrix in the fat QR decomposition of A, which\nimplies that the resulting matrix will be rectangular with the same\ndimensions as A\n;
qr;(matrix A);tuple(matrix, matrix);Returns both portions of the QR decomposition of A. The first element ("Q") is\nthe orthonormal matrix in the thin QR decomposition and the second element ("R")\nis upper triangular. This function is equivalent to `(qr_Q(A), qr_R(A))` but\nwith a lower computational cost due to the shared work between the two results.\nThe thin QR decomposition is always preferable because it will consume\nmuch less memory when the input matrix is large than will the fat QR\ndecomposition. Both versions of the decomposition represent the input\nmatrix as \begin{equation*} A = Q \, R. \end{equation*} Multiplying a column of an orthogonal\nmatrix by $-1$ still results in an orthogonal matrix, and you can\nmultiply the corresponding row of the upper trapezoidal matrix by $-1$\nwithout changing the product. Thus, Stan adopts the normalization that\nthe diagonal elements of the upper trapezoidal matrix are strictly\npositive and the columns of the orthogonal matrix are reflected if\nnecessary. Also, these QR  decomposition algorithms do not utilize\npivoting and thus may be  numerically unstable on input matrices that\nhave less than full rank.\n;
cholesky_decompose;(matrix A);matrix;The lower-triangular Cholesky factor of the symmetric\npositive-definite matrix A\n;
singular_values;(matrix A);vector;The singular values of `A` in descending order\n;
svd_U;(matrix A);matrix;The left-singular vectors of `A`\n;
svd_V;(matrix A);matrix;The right-singular vectors of `A`\n;
svd;(matrix A);tuple(matrix, vector, matrix);Returns a tuple containing the left-singular vectors of `A`, the\nsingular values of `A` in descending order, and the right-singular values of\n`A`. This function is equivalent to `(svd_U(A), singular_values(A), svd_V(A))`\nbut with a lower computational cost due to the shared work between the different\ncomponents.\n;
sort_asc;(vector v);vector;Sort the elements of v in ascending order\n;
sort_asc;(row_vector v);row_vector;Sort the elements of v in ascending order\n;
sort_desc;(vector v);vector;Sort the elements of v in descending order\n;
sort_desc;(row_vector v);row_vector;Sort the elements of v in descending order\n;
sort_indices_asc;(vector v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in ascending order.\n;
sort_indices_asc;(row_vector v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in ascending order.\n;
sort_indices_desc;(vector v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in descending order.\n;
sort_indices_desc;(row_vector v);array[] int;Return an array of indices between 1 and the size of v, sorted to\nindex v in descending order.\n;
rank;(vector v, int s);int;Number of components of v less than v[s]\n;
rank;(row_vector v, int s);int;Number of components of v less than v[s]\n;
reverse;(vector v);vector;Return a new vector containing the elements of the argument in reverse order.\n;
reverse;(row_vector v);row_vector;Return a new row vector containing the elements of the argument in reverse order.\n;
pareto;~;real;Increment target log probability density with `pareto_lupdf(y | y_min, alpha)`.;
pareto_lpdf;(reals y | reals y_min, reals alpha);real;The log of the Pareto density of y given positive minimum value y_min\nand shape alpha\n;
pareto_lupdf;(reals y | reals y_min, reals alpha);real;The log of the Pareto density of y given positive minimum value y_min\nand shape alpha dropping constant additive terms\n;
pareto_cdf;(reals y | reals y_min, reals alpha);real;The Pareto cumulative distribution function of y given positive\nminimum value y_min and shape alpha\n;
pareto_lcdf;(reals y | reals y_min, reals alpha);real;The log of the Pareto cumulative distribution function of y given\npositive minimum value y_min and shape alpha\n;
pareto_lccdf;(reals y | reals y_min, reals alpha);real;The log of the Pareto complementary cumulative distribution function\nof y given positive minimum value y_min and shape alpha\n;
pareto_rng;(reals y_min, reals alpha);R;Generate a Pareto variate with positive minimum value y_min and shape\nalpha may only be used in transformed data and generated quantities blocks. For a\ndescription of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
pareto_type_2;~;real;Increment target log probability density with `pareto_type_2_lupdf(y | mu, lambda, alpha)`.;
pareto_type_2_lpdf;(reals y | reals mu, reals lambda, reals alpha);real;The log of the Pareto Type 2 density of y given location mu, scale\nlambda, and shape alpha\n;
pareto_type_2_lupdf;(reals y | reals mu, reals lambda, reals alpha);real;The log of the Pareto Type 2 density of y given location mu, scale\nlambda, and shape alpha dropping constant additive terms\n;
pareto_type_2_cdf;(reals y | reals mu, reals lambda, reals alpha);real;The Pareto Type 2 cumulative distribution function of y given location\nmu, scale lambda, and shape alpha\n;
pareto_type_2_lcdf;(reals y | reals mu, reals lambda, reals alpha);real;The log of the Pareto Type 2 cumulative distribution function of y\ngiven location mu, scale lambda, and shape alpha\n;
pareto_type_2_lccdf;(reals y | reals mu, reals lambda, reals alpha);real;The log of the Pareto Type 2 complementary cumulative distribution\nfunction of y given location mu, scale lambda, and shape alpha\n;
pareto_type_2_rng;(reals mu, reals lambda, reals alpha);R;Generate a Pareto Type 2 variate with location mu, scale lambda, and\nshape alpha may only be used in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
wiener;~;real;Increment target log probability density with `wiener_lupdf(y | alpha, tau, beta, delta)`.;
wiener_lpdf;(reals y | reals alpha, reals tau, reals beta, reals delta);real;The log of the Wiener first passage time density of y given boundary\nseparation alpha, non-decision time tau, a-priori bias beta and drift\nrate delta\n;
wiener_lupdf;(reals y | reals alpha, reals tau, reals beta, reals delta);real;The log of the Wiener first passage time density of y given boundary\nseparation alpha, non-decision time tau, a-priori bias beta and drift\nrate delta dropping constant additive terms\n;
print;(T1 x1,..., TN xN);void;Print the values denoted by the arguments x1 through xN on the output\nmessage stream. There are no spaces between items in the print, but a\nline feed (LF Unicode U+000A C++ literal `'\n'`) is inserted at\nthe end of the printed line. The types `T1` through `TN` can be any of\nStan's built-in numerical types or double quoted strings of characters\n(bytes).\n;
reject;(T1 x1,..., TN xN);void;Reject the current iteration and print the values denoted by the\narguments x1 through xN on the output message stream. There are no\nspaces between items in the print, but a line feed (LF Unicode\nU+000A C++ literal `'\n'`) is inserted at the end of the printed\nline. The types `T1` through `TN` can be any of Stan's built-in\nnumerical types or double quoted strings of characters (bytes).\n;
to_matrix;(matrix m);matrix;Return the matrix `m` itself.\n;
to_matrix;(complex_matrix m);complex_matrix;Return the matrix `m` itself.\n;
to_matrix;(vector v);matrix;Convert the column vector `v` to a `size(v)` by 1 matrix.\n;
to_matrix;(complex_vector v);complex_matrix;Convert the column vector `v` to a `size(v)` by 1 matrix.\n;
to_matrix;(row_vector v);matrix;Convert the row vector `v` to a 1 by `size(v)` matrix.\n;
to_matrix;(complex_row_vector v);complex_matrix;Convert the row vector `v` to a 1 by `size(v)` matrix.\n;
to_matrix;(matrix M, int m, int n);matrix;Convert a matrix `A` to a matrix with `m` rows and `n` columns filled in\ncolumn-major order.\n;
to_matrix;(complex_matrix M, int m, int n);complex_matrix;Convert a matrix `A` to a matrix with `m` rows and `n` columns filled in\ncolumn-major order.\n;
to_matrix;(vector v, int m, int n);matrix;Convert a vector `v` to a matrix with `m` rows and `n` columns filled in\ncolumn-major order.\n;
to_matrix;(complex_vector v, int m, int n);complex_matrix;Convert a vector `v` to a matrix with `m` rows and `n` columns filled in\ncolumn-major order.\n;
to_matrix;(row_vector v, int m, int n);matrix;Convert a row_vector `v` to a matrix with `m` rows and `n` columns filled in\ncolumn-major order.\n;
to_matrix;(complex_row_vector v, int m, int n);complex_matrix;Convert a row vector `v` to a matrix with `m` rows and `n` columns filled in\ncolumn-major order.\n;
to_matrix;(matrix A, int m, int n, int col_major);matrix;Convert a matrix `A` to a matrix with `m` rows and `n` columns filled in\nrow-major order if `col_major` equals 0 (otherwise, they get filled in\ncolumn-major order).\n;
to_matrix;(complex_matrix A, int m, int n, int col_major);complex_matrix;Convert a matrix `A` to a matrix with `m` rows and `n` columns filled in\nrow-major order if `col_major` equals 0 (otherwise, they get filled in\ncolumn-major order).\n;
to_matrix;(vector v, int m, int n, int col_major);matrix;Convert a vector `v` to a matrix with `m` rows and `n` columns filled in\nrow-major order if `col_major` equals 0 (otherwise, they get filled in\ncolumn-major order).\n;
to_matrix;(complex_vector v, int m, int n, int col_major);complex_matrix;Convert a vector `v` to a matrix with `m` rows and `n` columns filled in\nrow-major order if `col_major` equals 0 (otherwise, they get filled in\ncolumn-major order).\n;
to_matrix;(row_vector v, int m, int n, int col_major);matrix;Convert a row vector `v` to a matrix with `m` rows and `n` columns filled in\nrow-major order if `col_major` equals 0 (otherwise, they get filled in\ncolumn-major order).\n;
to_matrix;(complex_row_vector v, int m, int n, int col_major);complex_matrix;Convert a row vector `v` to a matrix with `m` rows and `n` columns filled in\nrow-major order if `col_major` equals 0 (otherwise, they get filled in\ncolumn-major order).\n;
to_matrix;(array[] real a, int m, int n);matrix;Convert a one-dimensional array `a` to a matrix with `m` rows and `n`\ncolumns filled in column-major order.\n;
to_matrix;(array[] int a, int m, int n);matrix;Convert a one-dimensional array `a` to a matrix with `m` rows and `n`\ncolumns filled in column-major order.\n;
to_matrix;(array[] complex a, int m, int n);complex_matrix;Convert a one-dimensional array `a` to a matrix with `m` rows and `n`\ncolumns filled in column-major order.\n;
to_matrix;(array[] real a, int m, int n, int col_major);matrix;Convert a one-dimensional array `a` to a matrix with `m` rows and `n`\ncolumns filled in row-major order if `col_major` equals 0 (otherwise,\nthey get filled in column-major order).\n;
to_matrix;(array[] int a, int m, int n, int col_major);matrix;Convert a one-dimensional array `a` to a matrix with `m` rows and `n`\ncolumns filled in row-major order if `col_major` equals 0 (otherwise,\nthey get filled in column-major order).\n;
to_matrix;(array[] complex a, int m, int n, int col_major);complex_matrix;Convert a one-dimensional array `a` to a matrix with `m` rows and `n`\ncolumns filled in row-major order if `col_major` equals 0 (otherwise,\nthey get filled in column-major order).\n;
to_matrix;(array[] row_vector vs);matrix;Convert a one-dimensional array of row vectors to a matrix, where the size of\nthe array is the number of rows of the resulting matrix and the length of row\nvectors is the number of columns.\n;
to_matrix;(array[] complex_row_vector vs);complex_matrix;Convert a one-dimensional array of row vectors to a matrix, where the size of\nthe array is the number of rows of the resulting matrix and the length of row\nvectors is the number of columns.\n;
to_matrix;(array[,] real a);matrix;Convert the two dimensional array `a` to a matrix with the same\ndimensions and indexing order.\n;
to_matrix;(array[,] int a);matrix;Convert the two dimensional array `a` to a matrix with the same\ndimensions and indexing order. If any of the dimensions of `a` are zero,\nthe result will be a $0 \times 0$ matrix.\n;
to_matrix;(array[,] complex a );complex_matrix;Convert the two dimensional array `a` to a matrix with the same\ndimensions and indexing order.\n;
to_vector;(matrix m);vector;Convert the matrix `m` to a column vector in column-major order.\n;
to_vector;(complex_matrix m);complex_vector;Convert the matrix `m` to a column vector in column-major order.\n;
to_vector;(vector v);vector;Return the column vector `v` itself.\n;
to_vector;(complex_vector v);complex_vector;Return the column vector `v` itself.\n;
to_vector;(row_vector v);vector;Convert the row vector `v` to a column vector.\n;
to_vector;(complex_row_vector v);complex_vector;Convert the row vector `v` to a column vector.\n;
to_vector;(array[] real a);vector;Convert the one-dimensional array `a` to a column vector.\n;
to_vector;(array[] int a);vector;Convert the one-dimensional integer array `a` to a column vector.\n;
to_vector;(array[] complex a);complex_vector;Convert the one-dimensional complex array `a` to a column vector.\n;
to_row_vector;(matrix m);row_vector;Convert the matrix `m` to a row vector in column-major order.\n;
to_row_vector;(complex_matrix m);complex_row_vector;Convert the matrix `m` to a row vector in column-major order.\n;
to_row_vector;(vector v);row_vector;Convert the column vector `v` to a row vector.\n;
to_row_vector;(complex_vector v);complex_row_vector;Convert the column vector `v` to a row vector.\n;
to_row_vector;(row_vector v);row_vector;Return the row vector `v` itself.\n;
to_row_vector;(complex_row_vector v);complex_row_vector;Return the row vector `v` itself.\n;
to_row_vector;(array[] real a);row_vector;Convert the one-dimensional array `a` to a row vector.\n;
to_row_vector;(array[] int a);row_vector;Convert the one-dimensional array `a` to a row vector.\n;
to_row_vector;(array[] complex a);complex_row_vector;Convert the one-dimensional complex array `a` to a row vector.\n;
to_array_2d;(matrix m);array[,] real;Convert the matrix `m` to a two dimensional array with the same\ndimensions and indexing order.\n;
to_array_2d;(complex_matrix m);array[,] real;Convert the matrix `m` to a two dimensional array with the same\ndimensions and indexing order.\n;
to_array_1d;(vector v);array[] real;Convert the column vector `v` to a one-dimensional array.\n;
to_array_1d;(complex_vector v);array[] real;Convert the column vector `v` to a one-dimensional array.\n;
to_array_1d;(row_vector v);array[] real;Convert the row vector `v` to a one-dimensional array.\n;
to_array_1d;(complex_row_vector v);array[] complex;Convert the row vector `v` to a one-dimensional array.\n;
to_array_1d;(matrix m);array[] real;Convert the matrix `m` to a one-dimensional array in column-major order.\n;
to_array_1d;(complex_matrix m);array[] complex;Convert the matrix `m` to a one-dimensional array in column-major order.\n;
to_array_1d;(array[...] real a);array[] real;Convert the array `a` (of any dimension up to 10) to a one-dimensional\narray in row-major order.\n;
to_array_1d;(array[...] int a);array[] int;Convert the array `a` (of any dimension up to 10) to a one-dimensional\narray in row-major order.\n;
to_array_1d;(array[...] complex a);array[] complex;Convert the array `a` (of any dimension up to 10) to a one-dimensional\narray in row-major order.\n;
neg_binomial;~;real;Increment target log probability density with `neg_binomial_lupmf(n | alpha, beta)`.;
neg_binomial_lpmf;(ints n | reals alpha, reals beta);real;The log negative binomial probability mass of `n` given shape `alpha` and\ninverse scale `beta`\n;
neg_binomial_lupmf;(ints n | reals alpha, reals beta);real;The log negative binomial probability mass of `n` given shape `alpha` and\ninverse scale `beta` dropping constant additive terms\n;
neg_binomial_cdf;(ints n | reals alpha, reals beta);real;The negative binomial cumulative distribution function of `n` given\nshape `alpha` and inverse scale `beta`\n;
neg_binomial_lcdf;(ints n | reals alpha, reals beta);real;The log of the negative binomial cumulative distribution function of `n`\ngiven shape `alpha` and inverse scale `beta`\n;
neg_binomial_lccdf;(ints n | reals alpha, reals beta);real;The log of the negative binomial complementary cumulative distribution\nfunction of `n` given shape `alpha` and inverse scale `beta`\n;
neg_binomial_rng;(reals alpha, reals beta);R;Generate a negative binomial variate with shape `alpha` and inverse\nscale `beta` may only be used in transformed data and generated quantities blocks.\n`alpha` $/$ `beta` must be less than $2 ^ {29}$. For a description of argument and\nreturn types, see section [vectorized function signatures](conventions_for_probability_functions.qmd#prob-vectorization).\n;
neg_binomial_2;~;real;Increment target log probability density with `neg_binomial_2_lupmf(n | mu, phi)`.;
neg_binomial_2_lpmf;(ints n | reals mu, reals phi);real;The log negative binomial probability mass of `n` given location `mu` and\nprecision `phi`.\n;
neg_binomial_2_lupmf;(ints n | reals mu, reals phi);real;The log negative binomial probability mass of `n` given location `mu` and\nprecision `phi` dropping constant additive terms.\n;
neg_binomial_2_cdf;(ints n | reals mu, reals phi);real;The negative binomial cumulative distribution function of `n` given\nlocation `mu` and precision `phi`.\n;
neg_binomial_2_lcdf;(ints n | reals mu, reals phi);real;The log of the negative binomial cumulative distribution function of `n`\ngiven location `mu` and precision `phi`.\n;
neg_binomial_2_lccdf;(ints n | reals mu, reals phi);real;The log of the negative binomial complementary cumulative distribution\nfunction of `n` given location `mu` and precision `phi`.\n;
neg_binomial_2_rng;(reals mu, reals phi);R;Generate a negative binomial variate with location `mu` and precision\n`phi` may only be used in transformed data and generated quantities blocks. `mu`\nmust be less than $2 ^ {29}$. For a description of argument and return types, see\nsection [vectorized function signatures](conventions_for_probability_functions.qmd#prob-vectorization).\n;
neg_binomial_2_log;~;real;Increment target log probability density with `neg_binomial_2_log_lupmf(n | eta, phi)`.;
neg_binomial_2_log_lpmf;(ints n | reals eta, reals phi);real;The log negative binomial probability mass of `n` given log-location `eta`\nand inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_lupmf;(ints n | reals eta, reals phi);real;The log negative binomial probability mass of `n` given log-location `eta`\nand inverse overdispersion parameter `phi` dropping constant additive terms.\n;
neg_binomial_2_log_rng;(reals eta, reals phi);R;Generate a negative binomial variate with log-location `eta` and inverse\noverdispersion control `phi` may only be used in transformed data and generated\nquantities blocks. `eta` must be less than $29 \log 2$. For a description of\nargument and return types, see section [vectorized function signatures](conventions_for_probability_functions.qmd#prob-vectorization).\n;
neg_binomial_2_log_glm;~;real;Increment target log probability density with `neg_binomial_2_log_glm_lupmf(y | x, alpha, beta, phi)`.;
neg_binomial_2_log_glm_lpmf;(int y | matrix x, real alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_glm_lupmf;(int y | matrix x, real alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`\ndropping constant additive terms.\n;
neg_binomial_2_log_glm_lpmf;(int y | matrix x, vector alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_glm_lupmf;(int y | matrix x, vector alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`\ndropping constant additive terms.\n;
neg_binomial_2_log_glm_lpmf;(array[] int y | row_vector x, real alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_glm_lupmf;(array[] int y | row_vector x, real alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`\ndropping constant additive terms.\n;
neg_binomial_2_log_glm_lpmf;(array[] int y | row_vector x, vector alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_glm_lupmf;(array[] int y | row_vector x, vector alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`\ndropping constant additive terms.\n;
neg_binomial_2_log_glm_lpmf;(array[] int y | matrix x, real alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_glm_lupmf;(array[] int y | matrix x, real alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`\ndropping constant additive terms.\n;
neg_binomial_2_log_glm_lpmf;(array[] int y | matrix x, vector alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`.\n;
neg_binomial_2_log_glm_lupmf;(array[] int y | matrix x, vector alpha, vector beta, real phi);real;The log negative binomial probability mass of `y` given log-location\n`alpha + x * beta` and inverse overdispersion parameter `phi`\ndropping constant additive terms.\n;
poisson;~;real;Increment target log probability density with `poisson_lupmf(n | lambda)`.;
poisson_lpmf;(ints n | reals lambda);real;The log Poisson probability mass of n given rate lambda\n;
poisson_lupmf;(ints n | reals lambda);real;The log Poisson probability mass of n given rate lambda dropping constant\nadditive terms\n;
poisson_cdf;(ints n | reals lambda);real;The Poisson cumulative distribution function of n given rate lambda\n;
poisson_lcdf;(ints n | reals lambda);real;The log of the Poisson cumulative distribution function of n given\nrate lambda\n;
poisson_lccdf;(ints n | reals lambda);real;The log of the Poisson complementary cumulative distribution function\nof n given rate lambda\n;
poisson_rng;(reals lambda);R;Generate a Poisson variate with rate lambda may only be used in\ntransformed data and generated quantities blocks. lambda must be less than\n$2^{30}$. For a description of argument and return types, see section\n[vectorized function signatures](conventions_for_probability_functions.qmd#prob-vectorization).\n;
poisson_log;~;real;Increment target log probability density with `poisson_log_lupmf(n | alpha)`.;
poisson_log_lpmf;(ints n | reals alpha);real;The log Poisson probability mass of n given log rate alpha\n;
poisson_log_lupmf;(ints n | reals alpha);real;The log Poisson probability mass of n given log rate alpha dropping constant\nadditive terms\n;
poisson_log_rng;(reals alpha);R;Generate a Poisson variate with log rate alpha may only be used in\ntransformed data and generated quantities blocks. alpha must be less than\n$30 \log 2$. For a description of argument and return types, see section\n[vectorized function signatures](conventions_for_probability_functions.qmd#prob-vectorization).\n;
poisson_log_glm;~;real;Increment target log probability density with `poisson_log_glm_lupmf(y | x, alpha, beta)`.;
poisson_log_glm_lpmf;(int y | matrix x, real alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`.\n;
poisson_log_glm_lupmf;(int y | matrix x, real alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`\ndropping constant additive terms.\n;
poisson_log_glm_lpmf;(int y | matrix x, vector alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`.\n;
poisson_log_glm_lupmf;(int y | matrix x, vector alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`\ndropping constant additive terms.\n;
poisson_log_glm_lpmf;(array[] int y | row_vector x, real alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`.\n;
poisson_log_glm_lupmf;(array[] int y | row_vector x, real alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`\ndropping constant additive terms.\n;
poisson_log_glm_lpmf;(array[] int y | row_vector x, vector alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`.\n;
poisson_log_glm_lupmf;(array[] int y | row_vector x, vector alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`\ndropping constant additive terms.\n;
poisson_log_glm_lpmf;(array[] int y | matrix x, real alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`.\n;
poisson_log_glm_lupmf;(array[] int y | matrix x, real alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`\ndropping constant additive terms.\n;
poisson_log_glm_lpmf;(array[] int y | matrix x, vector alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`.\n;
poisson_log_glm_lupmf;(array[] int y | matrix x, vector alpha, vector beta);real;The log Poisson probability mass of `y` given the log-rate `alpha + x * beta`\ndropping constant additive terms.\n;
lkj_corr;~;real;Increment target log probability density with `lkj_corr_lupdf(y | eta)`.;
lkj_corr_lpdf;(matrix y | real eta);real;The log of the LKJ density for the correlation matrix y given\nnonnegative shape eta. `lkj_corr_cholesky_lpdf` is faster, more numerically\nstable, uses less memory, and should be preferred to this.\n;
lkj_corr_lupdf;(matrix y | real eta);real;The log of the LKJ density for the correlation matrix y given\nnonnegative shape eta dropping constant additive terms.\n`lkj_corr_cholesky_lupdf` is faster, more numerically stable, uses less memory,\nand should be preferred to this.\n;
lkj_corr_rng;(int K, real eta);matrix;Generate a LKJ random correlation matrix of order K with shape eta\nmay only be used in transformed data and generated quantities blocks\n;
lkj_corr_cholesky;~;real;Increment target log probability density with `lkj_corr_cholesky_lupdf(L | eta)`.;
lkj_corr_cholesky_lpdf;(matrix L | real eta);real;The log of the LKJ density for the lower-triangular Cholesky factor L\nof a correlation matrix given shape eta\n;
lkj_corr_cholesky_lupdf;(matrix L | real eta);real;The log of the LKJ density for the lower-triangular Cholesky factor L\nof a correlation matrix given shape eta dropping constant additive terms\n;
lkj_corr_cholesky_rng;(int K, real eta);matrix;Generate a random Cholesky factor of a correlation matrix of order K\nthat is distributed LKJ with shape eta may only be used in transformed data\nand generated quantities blocks\n;
bernoulli;~;real;{{< since 2.0 >}};
bernoulli_lpmf;(ints y | reals theta);real;The log Bernoulli probability mass of y given chance of success `theta`\n;
bernoulli_lupmf;(ints y | reals theta);real;The log Bernoulli probability mass of y given chance of success theta\ndropping constant additive terms\n;
bernoulli_cdf;(ints y | reals theta);real;The Bernoulli cumulative distribution function of y given chance of\nsuccess `theta`\n;
bernoulli_lcdf;(ints y | reals theta);real;The log of the Bernoulli cumulative distribution function of y given\nchance of success `theta`\n;
bernoulli_lccdf;(ints y | reals theta);real;The log of the Bernoulli complementary cumulative distribution\nfunction of y given chance of success `theta`\n;
bernoulli_rng;(reals theta);R;Generate a Bernoulli variate with chance of success `theta` may only be\nused in transformed data and generated quantities blocks.\nFor a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
bernoulli_logit;~;real;{{< since 2.0 >}};
bernoulli_logit_lpmf;(ints y | reals alpha);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha)`\n;
bernoulli_logit_lupmf;(ints y | reals alpha);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha)` dropping constant additive terms\n;
bernoulli_logit_rng;(reals alpha);R;Generate a Bernoulli variate with chance of success\n$\text{logit}^{-1}(\alpha)$ may only be used in transformed data and generated\nquantities blocks. For a description of argument and return types, see section\n[vectorized PRNG functions](conventions_for_probability_functions.qmd#prng-vectorization).\n;
bernoulli_logit_glm;~;real;{{< since 2.25 >}};
bernoulli_logit_glm_lpmf;(int y | matrix x, real alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)`.\n;
bernoulli_logit_glm_lupmf;(int y | matrix x, real alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
bernoulli_logit_glm_lpmf;(int y | matrix x, vector alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)`.\n;
bernoulli_logit_glm_lupmf;(int y | matrix x, vector alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
bernoulli_logit_glm_lpmf;(array[] int y | row_vector x, real alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)`.\n;
bernoulli_logit_glm_lupmf;(array[] int y | row_vector x, real alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
bernoulli_logit_glm_lpmf;(array[] int y | row_vector x, vector alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)`.\n;
bernoulli_logit_glm_lupmf;(array[] int y | row_vector x, vector alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
bernoulli_logit_glm_lpmf;(array[] int y | matrix x, real alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)`.\n;
bernoulli_logit_glm_lupmf;(array[] int y | matrix x, real alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
bernoulli_logit_glm_lpmf;(array[] int y | matrix x, vector alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)`.\n;
bernoulli_logit_glm_lupmf;(array[] int y | matrix x, vector alpha, vector beta);real;The log Bernoulli probability mass of y given chance of success\n`inv_logit(alpha + x * beta)` dropping constant additive terms.\n;
bernoulli_logit_glm_rng;(matrix x, vector alpha, vector beta);array[] int;Generate an array of Bernoulli variates with chances of success\n`inv_logit(alpha + x * beta)` may only be used in transformed data and generated\nquantities blocks.\n;
bernoulli_logit_glm_rng;(row_vector x, vector alpha, vector beta);array[] int;Generate an array of Bernoulli variates with chances of success\n`inv_logit(alpha + x * beta)` may only be used in transformed data and generated\nquantities blocks.\n;
num_elements;(complex_vector x);int;The total number of elements in the vector x (same as function `rows`)\n;
num_elements;(complex_row_vector x);int;The total number of elements in the vector x (same as function `cols`)\n;
num_elements;(complex_matrix x);int;The total number of elements in the matrix x. For example, if `x` is a\n$5 \times 3$ matrix, then `num_elements(x)` is 15\n;
rows;(complex_vector x);int;The number of rows in the vector x\n;
rows;(complex_row_vector x);int;The number of rows in the row vector x, namely 1\n;
rows;(complex_matrix x);int;The number of rows in the matrix x\n;
cols;(complex_vector x);int;The number of columns in the vector x, namely 1\n;
cols;(complex_row_vector x);int;The number of columns in the row vector x\n;
cols;(complex_matrix x);int;The number of columns in the matrix x\n;
size;(complex_vector x);int;The size of `x`, i.e., the number of elements\n;
size;(complex_row_vector x);int;The size of `x`, i.e., the number of elements\n;
size;(matrix x);int;The size of the matrix `x`.  For example, if `x` is a\n$5 \times 3$ matrix, then `size(x)` is 15.\n;
operator-;(complex_vector x);complex_vector;The negation of the vector x.\n;
operator-;(complex_row_vector x);complex_row_vector;The negation of the row vector x.\n;
operator-;(complex_matrix x);complex_matrix;The negation of the matrix x.\n;
operator-;(T x);T;Vectorized version of `operator-`. If `T x` is a (possibly nested) array of\nmatrix types, `-x` is the same shape array where each individual value is negated.\n;
operator+;(complex_vector x, complex_vector y);complex_vector;The sum of the vectors x and y.\n;
operator+;(complex_row_vector x, complex_row_vector y);complex_row_vector;The sum of the row vectors x and y.\n;
operator+;(complex_matrix x, complex_matrix y);complex_matrix;The sum of the matrices x and y\n;
operator-;(complex_vector x, complex_vector y);complex_vector;The difference between the vectors x and y.\n;
operator-;(complex_row_vector x, complex_row_vector y);complex_row_vector;The difference between the row vectors x and y\n;
operator-;(complex_matrix x, complex_matrix y);complex_matrix;The difference between the matrices x and y\n;
operator*;(complex x, complex_vector y);complex_vector;The product of the scalar x and vector y\n;
operator*;(complex x, complex_row_vector y);complex_row_vector;The product of the scalar x and the row vector y\n;
operator*;(complex x, complex_matrix y);complex_matrix;The product of the scalar x and the matrix y\n;
operator*;(complex_vector x, complex y);complex_vector;The product of the scalar y and vector x\n;
operator*;(complex_vector x, complex_row_vector y);complex_matrix;The product of the vector x and row vector y\n;
operator*;(complex_row_vector x, complex y);complex_row_vector;The product of the scalar y and row vector x\n;
operator*;(complex_row_vector x, complex_vector y);complex;The product of the row vector x and vector y\n;
operator*;(complex_row_vector x, complex_matrix y);complex_row_vector;The product of the row vector x and matrix y\n;
operator*;(complex_matrix x, complex y);complex_matrix;The product of the scalar y and matrix x\n;
operator*;(complex_matrix x, complex_vector y);complex_vector;The product of the matrix x and vector y\n;
operator*;(complex_matrix x, complex_matrix y);complex_matrix;The product of the matrices x and y\n;
operator+;(complex_vector x, complex y);complex_vector;The result of adding y to every entry in the vector x\n;
operator+;(complex x, complex_vector y);complex_vector;The result of adding x to every entry in the vector y\n;
operator+;(complex_row_vector x, complex y);complex_row_vector;The result of adding y to every entry in the row vector x\n;
operator+;(complex x, complex_row_vector y);complex_row_vector;The result of adding x to every entry in the row vector y\n;
operator+;(complex_matrix x, complex y);complex_matrix;The result of adding y to every entry in the matrix x\n;
operator+;(complex x, complex_matrix y);complex_matrix;The result of adding x to every entry in the matrix y\n;
operator-;(complex_vector x, complex y);complex_vector;The result of subtracting y from every entry in the vector x\n;
operator-;(complex x, complex_vector y);complex_vector;The result of adding x to every entry in the negation of the vector y\n;
operator-;(complex_row_vector x, complex y);complex_row_vector;The result of subtracting y from every entry in the row vector x\n;
operator-;(complex x, complex_row_vector y);complex_row_vector;The result of adding x to every entry in the negation of the row vector y\n;
operator-;(complex_matrix x, complex y);complex_matrix;The result of subtracting y from every entry in the matrix x\n;
operator-;(complex x, complex_matrix y);complex_matrix;The result of adding x to every entry in negation of the matrix y\n;
operator/;(complex_vector x, complex y);complex_vector;The result of dividing each entry in the vector x by y\n;
operator/;(complex_row_vector x, complex y);complex_row_vector;The result of dividing each entry in the row vector x by y\n;
operator/;(complex_matrix x, complex y);complex_matrix;The result of dividing each entry in the matrix x by y\n;
operator';(complex_matrix x);complex_matrix;The transpose of the matrix `x`, written as `x'`\n;
operator';(complex_vector x);complex_row_vector;The transpose of the vector `x`, written as `x'`\n;
operator';(complex_row_vector x);complex_vector;The transpose of the row vector `x`, written as `x'`\n;
operator.*;(complex_vector x, complex_vector y);complex_vector;The elementwise product of `x` and `y`\n;
operator.*;(complex_row_vector x, complex_row_vector y);complex_row_vector;The elementwise product of `x` and `y`\n;
operator.*;(complex_matrix x, complex_matrix y);complex_matrix;The elementwise product of `x` and `y`\n;
operator./;(complex_vector x, complex_vector y);complex_vector;The elementwise quotient of `x` and `y`\n;
operator./;(complex x, complex_vector y);complex_vector;The elementwise quotient of `x` and `y`\n;
operator./;(complex_vector x, complex y);complex_vector;The elementwise quotient of `x` and `y`\n;
operator./;(complex_row_vector x, complex_row_vector y);complex_row_vector;The elementwise quotient of `x` and `y`\n;
operator./;(complex x, complex_row_vector y);complex_row_vector;The elementwise quotient of `x` and `y`\n;
operator./;(complex_row_vector x, complex y);complex_row_vector;The elementwise quotient of `x` and `y`\n;
operator./;(complex_matrix x, complex_matrix y);complex_matrix;The elementwise quotient of `x` and `y`\n;
operator./;(complex x, complex_matrix y);complex_matrix;The elementwise quotient of `x` and `y`\n;
operator./;(complex_matrix x, complex y);complex_matrix;The elementwise quotient of `x` and `y`\n;
operator.^;(complex_vector x, complex_vector y);complex_vector;The elementwise power of y and x\n;
operator.^;(complex_vector x, complex y);complex_vector;The elementwise power of y and x\n;
operator.^;(complex x, complex_vector y);complex_vector;The elementwise power of y and x\n;
operator.^;(complex_row_vector x, complex_row_vector y);complex_row_vector;The elementwise power of y and x\n;
operator.^;(complex_row_vector x, complex y);complex_row_vector;The elementwise power of y and x\n;
operator.^;(complex x, complex_row_vector y);complex_row_vector;The elementwise power of y and x\n;
operator.^;( complex_matrix x, complex_matrix y);complex_matrix;The elementwise power of y and x\n;
operator.^;( complex_matrix x, complex y);complex_matrix;The elementwise power of y and x\n;
operator.^;(complex x, complex_matrix y);complex_matrix;The elementwise power of y and x\n;
dot_product;(complex_vector x, complex_vector y);complex;The dot product of x and y\n;
dot_product;(complex_vector x, complex_row_vector y);complex;The dot product of x and y\n;
dot_product;(complex_row_vector x, complex_vector y);complex;The dot product of x and y\n;
dot_product;(complex_row_vector x, complex_row_vector y);complex;The dot product of x and y\n;
columns_dot_product;(complex_vector x, complex_vector y);complex_row_vector;The dot product of the columns of x and y\n;
columns_dot_product;(complex_row_vector x, complex_row_vector y);complex_row_vector;The dot product of the columns of x and y\n;
columns_dot_product;(complex_matrix x, complex_matrix y);complex_row_vector;The dot product of the columns of x and y\n;
rows_dot_product;(complex_vector x, complex_vector y);complex_vector;The dot product of the rows of x and y\n;
rows_dot_product;(complex_row_vector x, complex_row_vector y);complex_vector;The dot product of the rows of x and y\n;
rows_dot_product;(complex_matrix x, complex_matrix y);complex_vector;The dot product of the rows of x and y\n;
dot_self;(complex_vector x);complex;The dot product of the vector x with itself\n;
dot_self;(complex_row_vector x);complex;The dot product of the row vector x with itself\n;
columns_dot_self;(complex_vector x);complex_row_vector;The dot product of the columns of x with themselves\n;
columns_dot_self;(complex_row_vector x);complex_row_vector;The dot product of the columns of x with themselves\n;
columns_dot_self;(complex_matrix x);complex_row_vector;The dot product of the columns of x with themselves\n;
rows_dot_self;(complex_vector x);complex_vector;The dot product of the rows of x with themselves\n;
rows_dot_self;(complex_row_vector x);complex_vector;The dot product of the rows of x with themselves\n;
rows_dot_self;(complex_matrix x);complex_vector;The dot product of the rows of x with themselves\n;
diag_pre_multiply;(complex_vector v, complex_matrix m);complex_matrix;Return the product of the diagonal matrix formed from the vector v and\nthe matrix m, i.e., `diag_matrix(v) * m`.\n;
diag_pre_multiply;(complex_row_vector v, complex_matrix m);complex_matrix;Return the product of the diagonal matrix formed from the vector rv\nand the matrix m, i.e., `diag_matrix(rv) * m`.\n;
diag_post_multiply;(complex_matrix m, complex_vector v);complex_matrix;Return the product of the matrix m and the diagonal matrix formed from\nthe vector v, i.e., `m * diag_matrix(v)`.\n;
diag_post_multiply;(complex_matrix m, complex_row_vector v);complex_matrix;Return the product of the matrix `m` and the diagonal matrix formed\nfrom the the row vector `rv`, i.e., `m * diag_matrix(rv)`.\n;
sum;(complex_vector x);complex;The sum of the values in x, or 0 if x is empty\n;
sum;(complex_row_vector x);complex;The sum of the values in x, or 0 if x is empty\n;
sum;(complex_matrix x);complex;The sum of the values in x, or 0 if x is empty\n;
prod;(complex_vector x);complex;The product of the values in x, or 1 if x is empty\n;
prod;(complex_row_vector x);complex;The product of the values in x, or 1 if x is empty\n;
prod;(complex_matrix x);complex;The product of the values in x, or 1 if x is empty\n;
get_real;(T x);T;Given an object of complex type `T`, return the same shape object but of type\n`real` by getting the real component of each element of `x`.\n;
get_imag;(T x);T;Given an object of complex type `T`, return the same shape object but of type\n`real` by getting the imaginary component of each element of `x`.\nFor example, given the Stan declaration\n```stan\n  complex_vector[2] z = [3+4i, 5+6i]'\n```\nA call `get_real(z)` will yield the vector `[3, 5]'`, and a call `get_imag(z)`\nwill yield the vector `[4, 6]'`.\n;
rep_vector;(complex z, int m);complex_vector;Return the size m (column) vector consisting of copies of z.\n;
rep_row_vector;(complex z, int n);complex_row_vector;Return the size n row vector consisting of copies of z.\n;
rep_matrix;(complex z, int m, int n);complex_matrix;Return the m by n matrix consisting of copies of z.\n;
rep_matrix;(complex_vector v, int n);complex_matrix;Return the m by n matrix consisting of n copies of the (column) vector v of size m.\n;
rep_matrix;(complex_row_vector rv, int m);complex_matrix;Return the m by n matrix consisting of m copies of the row vector rv of size n.\n;
symmetrize_from_lower_tri;(complex_matrix A);complex_matrix;Construct a symmetric matrix from the lower triangle of A.\n;
add_diag;(complex_matrix m, complex_row_vector d);complex_matrix;Add row_vector `d` to the diagonal of matrix `m`.\n;
add_diag;(complex_matrix m, complex_vector d);complex_matrix;Add vector `d` to the diagonal of matrix `m`.\n;
add_diag;(complex_matrix m, complex_real d);complex_matrix;Add scalar `d` to every diagonal element of matrix `m`.\n;
diagonal;(complex_matrix x);complex_vector;The diagonal of the matrix x\n;
diag_matrix;(complex_vector x);complex_matrix;The diagonal matrix with diagonal x\n;
col;(complex_matrix x, int n);complex_vector;The n-th column of matrix x\n;
row;(complex_matrix x, int m);complex_row_vector;The m-th row of matrix x\n;
block;(complex_matrix x, int i, int j, int n_rows, int n_cols);complex_matrix;Return the submatrix of x that starts at row i and column j and extends n_rows rows and n_cols columns.\n;
sub_col;(complex_matrix x, int i, int j, int n_rows);complex_vector;Return the sub-column of x that starts at row i and column j and extends n_rows rows and 1 column.\n;
sub_row;(complex_matrix x, int i, int j, int n_cols);complex_row_vector;Return the sub-row of x that starts at row i and column j and extends 1 row and n_cols columns.\n;
head;(complex_vector v, int n);complex_vector;Return the vector consisting of the first n elements of v.\n;
head;(complex_row_vector rv, int n);complex_row_vector;Return the row vector consisting of the first n elements of rv.\n;
tail;(complex_vector v, int n);complex_vector;Return the vector consisting of the last n elements of v.\n;
tail;(complex_row_vector rv, int n);complex_row_vector;Return the row vector consisting of the last n elements of rv.\n;
segment;(complex_vector v, int i, int n);complex_vector;Return the vector consisting of the n elements of v starting at i i.e.,\nelements i through through i + n - 1.\n;
segment;(complex_row_vector rv, int i, int n);complex_row_vector;Return the row vector consisting of the n elements of rv starting at i i.e.,\nelements i through through i + n - 1.\n;
append_col;(complex_matrix x, complex_matrix y);complex_matrix;Combine matrices x and y by column. The matrices must have the same number of\nrows.\n;
append_col;(complex_matrix x, complex_vector y);complex_matrix;Combine matrix x and vector y by column. The matrix and the vector must have\nthe same number of rows.\n;
append_col;(complex_vector x, complex_matrix y);complex_matrix;Combine vector x and matrix y by column. The vector and the matrix must have\nthe same number of rows.\n;
append_col;(complex_vector x, complex_vector y);complex_matrix;Combine vectors x and y by column. The vectors must have the same number of\nrows.\n;
append_col;(complex_row_vector x, complex_row_vector y);complex_row_vector;Combine row vectors x and y (of any size) into another row vector by appending y\nto the end of x.\n;
append_col;(complex x, complex_row_vector y);complex_row_vector;Append x to the front of y, returning another row vector.\n;
append_col;(complex_row_vector x, complex y);complex_row_vector;Append y to the end of x, returning another row vector.\n;
append_row;(complex_matrix x, complex_matrix y);complex_matrix;Combine matrices x and y by row. The matrices must have the same number of\ncolumns.\n;
append_row;(complex_matrix x, complex_row_vector y);complex_matrix;Combine matrix x and row vector y by row. The matrix and the row vector must\nhave the same number of columns.\n;
append_row;(complex_row_vector x, complex_matrix y);complex_matrix;Combine row vector x and matrix y by row. The row vector and the matrix must\nhave the same number of columns.\n;
append_row;(complex_row_vector x, complex_row_vector y);complex_matrix;Combine row vectors x and y by row. The row vectors must have the same number\nof columns.\n;
append_row;(complex_vector x, complex_vector y);complex_vector;Concatenate vectors x and y of any size into another vector.\n;
append_row;(complex x, complex_vector y);complex_vector;Append x to the top of y, returning another vector.\n;
append_row;(complex_vector x, complex y);complex_vector;Append y to the bottom of x, returning another vector.\n;
fft;(complex_vector v);complex_vector;Return the discrete Fourier transform of the specified complex vector `v`.\nIf $v \in \mathbb{C}^N$ is a complex vector with $N$ elements and $u =\n\textrm{fft}(v)$, then\n\begin{equation*}\nu_n = \sum_{m < n}\nv_m \cdot\n\exp\left(\frac{-n \cdot m \cdot 2 \cdot \pi \cdot \sqrt{-1}}{N}\right).\n\end{equation*}\n;
fft2;(complex_matrix m);complex_matrix;Return the 2D discrete Fourier transform of the specified complex\nmatrix `m`.  The 2D FFT is defined as the result of applying the FFT\nto each row and then to each column.\n;
inv_fft;(complex_vector u);complex_vector;Return the inverse of the discrete Fourier transform of the specified complex\nvector `u`.  The inverse FFT (this function) is scaled so that\n`fft(inv_fft(u)) == u`.  If $u \in \mathbb{C}^N$ is a complex vector\nwith $N$ elements and $v = \textrm{fft}^{-1}(u)$, then\n\begin{equation*}\nv_n =  \frac{1}{N} \sum_{m < n}\nu_m \cdot\n\exp\left(\frac{n \cdot m \cdot 2 \cdot \pi \cdot \sqrt{-1}}{N}\right).\n\end{equation*}\nThis only differs from the FFT by the sign inside the exponential and\nthe scaling.  The $\frac{1}{N}$ scaling ensures that `fft(inv_fft(u))\n== u` and `inv_fft(fft(v)) == v` for complex vectors `u` and `v`.\n;
inv_fft2;(complex_matrix m);complex_matrix;Return the inverse of the 2D discrete Fourier transform of the\nspecified complex matrix `m`.  The 2D inverse FFT is defined as the\nresult of applying the inverse FFT to each row and then to each\ncolumn. The invertible scaling of the inverse FFT ensures\n`fft2(inv_fft2(A)) == A` and `inv_fft2(fft2(B)) == B`.\n;
cumulative_sum;(array[] complex x);array[] complex;The cumulative sum of x\n;
cumulative_sum;(complex_vector v);complex_vector;The cumulative sum of v\n;
cumulative_sum;(complex_row_vector rv);complex_row_vector;The cumulative sum of rv\n;
operator/;(complex_row_vector b, complex_matrix A);complex_row_vector;The right division of b by A equivalently `b * inverse(A)`\n;
operator/;(complex_matrix B, complex_matrix A);complex_matrix;The right division of B by A equivalently `B * inverse(A)`\n;
trace;(complex_matrix A);complex;The trace of A, or 0 if A is empty A is not required to be diagonal\n;
eigenvalues;(complex_matrix A);complex_vector;The complex-valued vector of eigenvalues of the matrix `A`. The eigenvalues are\nrepeated according to their algebraic multiplicity, so there are as many\neigenvalues as rows in the matrix. The eigenvalues are not sorted in any\nparticular order.\n;
eigenvectors;(complex_matrix A);complex_matrix;The matrix with the complex-valued (column) eigenvectors of the matrix `A` in the\nsame order as returned by the function `eigenvalues`\n;
eigendecompose;(complex_matrix A);tuple(complex_matrix, complex_vector);Return the matrix of (column) eigenvectors and vector of eigenvalues of the\nmatrix `A`. This function is equivalent to `(eigenvectors(A), eigenvalues(A))`\nbut with a lower computational cost due to the shared work between the two\nresults.\n;
eigenvalues_sym;(complex_matrix A);complex_vector;The vector of eigenvalues of a symmetric matrix `A` in ascending order\n;
eigenvectors_sym;(complex_matrix A);complex_matrix;The matrix with the (column) eigenvectors of symmetric matrix `A` in the\nsame order as returned by the function `eigenvalues_sym`\n;
eigendecompose_sym;(complex_matrix A);tuple(complex_matrix, complex_vector);Return the matrix of (column) eigenvectors and vector of eigenvalues of the\nsymmetric matrix `A`. This function is equivalent to `(eigenvectors_sym(A),\neigenvalues_sym(A))` but with a lower computational cost due to the shared work\nbetween the two results.\nBecause multiplying an eigenvector by $-1$ results in an eigenvector,\neigenvectors returned by a decomposition are only identified up to a\nsign change.  In order to compare the eigenvectors produced by Stan's\neigendecomposition to others, signs may need to be normalized in some\nway, such as by fixing the sign of a component, or doing comparisons\nallowing a multiplication by $-1$.\nThe condition number of a symmetric matrix is defined to be the ratio\nof the largest eigenvalue to the smallest eigenvalue.  Large condition\nnumbers lead to difficulty in numerical algorithms such as computing\ninverses, and thus known as "ill conditioned."  The ratio can even be\ninfinite in the case of singular matrices (i.e., those with\neigenvalues of 0).\n;
singular_values;(complex_matrix A);vector;The singular values of `A` in descending order\n;
svd_U;(complex_matrix A);complex_matrix;The left-singular vectors of `A`\n;
svd_V;(complex_matrix A);complex_matrix;The right-singular vectors of `A`\n;
svd;(complex_matrix A);tuple(complex_matrix, vector, complex_matrix);Returns a tuple containing the left-singular vectors of `A`, the\nsingular values of `A` in descending order, and the right-singular values of\n`A`. This function is equivalent to `(svd_U(A), singular_values(A), svd_V(A))`\nbut with a lower computational cost due to the shared work between the different\ncomponents.\n;
complex_schur_decompose_t;(matrix A);complex_matrix;Compute the upper-triangular Schur form matrix of the complex Schur decomposition of `A`.\n;
complex_schur_decompose_t;(complex_matrix A);complex_matrix;Compute the upper-triangular Schur form matrix of the complex Schur decomposition of `A`.\n;
complex_schur_decompose_u;(matrix A);complex_matrix;Compute the unitary matrix of the complex Schur decomposition of `A`.\n;
complex_schur_decompose_u;(complex_matrix A);complex_matrix;Compute the unitary matrix of the complex Schur decomposition of `A`.\n;
complex_schur_decompose;(matrix A);tuple(complex_matrix, complex_matrix);Returns the unitary matrix and the upper-triangular Schur form matrix of the\ncomplex Schur decomposition of `A`. This function is equivalent to\n`(complex_schur_decompose_u(A), complex_schur_decompose_t(A))` but with a lower\ncomputational cost due to the shared work between the two results.\nThis overload is equivalent to `complex_schur_decompose(to_complex(A,0))` but is\nmore efficient.\n;
complex_schur_decompose;(complex_matrix A);tuple(complex_matrix, complex_matrix);Returns the unitary matrix and the upper-triangular Schur form matrix of the\ncomplex Schur decomposition of `A`. This function is equivalent to\n`(complex_schur_decompose_u(A), complex_schur_decompose_t(A))` but with a lower\ncomputational cost due to the shared work between the two results.\n;
reverse;(complex_vector v);complex_vector;Return a new vector containing the elements of the argument in reverse order.\n;
reverse;(complex_row_vector v);complex_row_vector;Return a new row vector containing the elements of the argument in reverse\n order.\n {{< since 2.30 >}}\n;
